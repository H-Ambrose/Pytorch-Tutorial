{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出图片的大小\n",
    "imsize = 512 if torch.cuda.is_available() else 128  # use small size if no gpu\n",
    "\n",
    "# 改变图片大小\n",
    "loader = transforms.Compose([\n",
    "    transforms.Resize(imsize),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    # unsqueeze(n) 在第n维上增加维度\n",
    "    image = loader(image).unsqueeze(0)\n",
    "    return image.to(device, torch.float)\n",
    "\n",
    "style_img = image_loader(\"./data/images/neural-style/picasso.jpg\")\n",
    "content_img = image_loader(\"./data/images/neural-style/dancing.jpg\")\n",
    "\n",
    "assert style_img.size() == content_img.size(), \\\n",
    "\"we need to import style and content images of the same size\"\n",
    "\n",
    "# assert（断言）用于判断一个表达式，在表达式条件为 false 的时候触发异常。\n",
    "\n",
    "\n",
    "\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        # 我们从用于动态计算梯度的树中“分离”目标内容：\n",
    "        # 这是一个声明的值，而不是变量。否则标准的正向方法将引发错误。 \n",
    "        self.target = target.detach()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.loss = F.mse_loss(input, self.target)\n",
    "        return input\n",
    "\n",
    "    \n",
    "    \n",
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()\n",
    "    # a = batch size(=1)\n",
    "    # b = number(特征映射) \n",
    "    # (c,d) = dimensions of a f. map (N=c*d)\n",
    "    \n",
    "    features = input.view(a * b, c * d)\n",
    "    \n",
    "    G = torch.mm(features, features.t())\n",
    "    \n",
    "    return G.div(a * b * c * d)\n",
    "\n",
    "\n",
    "\n",
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self, target_feature):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = gram_matrix(target_feature).detach()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        G = gram_matrix(input)\n",
    "        self.loss = F.mse_loss(G, self.target)\n",
    "        return input\n",
    "\n",
    "\n",
    "\n",
    "cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "\n",
    "# 创建一个模块来规范化输入图像 \n",
    "# 这样就可以轻松地将它放入nn.Sequential中 \n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalization, self).__init__()\n",
    "        self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
    "        self.std = torch.tensor(std).view(-1, 1, 1)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        return (img - self.mean) / self.std\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layers_default = ['conv_4']\n",
    "style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "\n",
    "def get_style_model_and_losses(cnn, normalization_mean, normalization_std, \n",
    "                               style_img, content_img, \n",
    "                               content_layers = content_layers_default,\n",
    "                               style_layers = style_layers_default):\n",
    "    cnn = copy.deepcopy(cnn)\n",
    "    \n",
    "    normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
    "    \n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "    \n",
    "    # 创建一个新的nn.Sequential来放入应该按顺序激活的模块 \n",
    "    model = nn.Sequential(normalization)\n",
    "    \n",
    "    i = 0 # 记录conv层的数量\n",
    "    for layer in cnn.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            i += 1\n",
    "            name = 'conv_{}'.format(i)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            name = 'relu_{}'.format(i)\n",
    "            layer = nn.ReLU(inplace = False)\n",
    "            # inplace-选择是否进行覆盖运算\n",
    "            # 从上层网络Conv2d中传递下来的tensor直接进行修改，这样能够节省运算内存，不用多存储其他变量\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            name = 'pool_{}'.format(i)\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            name = 'bn_{}'.format(i)\n",
    "        else:\n",
    "            raise RuntimeError('Unrecognized layer:{}'.format(layer.__class__.__name__))\n",
    "        model.add_module(name, layer)\n",
    "        \n",
    "        if name in content_layers:\n",
    "            target = model(content_img).detach()\n",
    "            content_loss = ContentLoss(target)\n",
    "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
    "            content_losses.append(content_loss)\n",
    "                \n",
    "        if name in style_layers:\n",
    "            target_feature = model(style_img).detach()\n",
    "            style_loss = StyleLoss(target_feature)\n",
    "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "        \n",
    "        for i in range (len(model) - 1, -1, -1):\n",
    "            if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
    "                break\n",
    "        \n",
    "        model = model[:(i + 1)]\n",
    "        \n",
    "        return model, style_losses, content_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_style_transfer(cnn, normalization_mean, normalizartion_std,\n",
    "                       content_img, style_img, input_img, num_steps = 100,\n",
    "                       style_weight = 1000000, content_weight = 1):\n",
    "    print(\"Building the style tranfer model ...\")\n",
    "    model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
    "                                                                     normalization_mean, normalizartion_std, \n",
    "                                                                     style_img, content_img) \n",
    "    optimizer = get_input_optimizer(input_img)\n",
    "    \n",
    "    print(\"Optimizing ...\")\n",
    "    run = [0]\n",
    "    while run[0] <= num_steps:\n",
    "        # 更正更新的输入图像的值\n",
    "        def closure():\n",
    "            input_img.data.clamp_(0, 1)\n",
    "            optimizer.zero_grad()\n",
    "            model(input_img)\n",
    "            style_score = 0\n",
    "            content_score = 0\n",
    "            \n",
    "            for sl in style_losses:\n",
    "                style_score += sl.loss\n",
    "            for cl in content_losses:\n",
    "                content_score += cl.loss\n",
    "            \n",
    "            style_score *= style_weight\n",
    "            content_score *= content_weight\n",
    "            loss = style_score + content_score\n",
    "            loss.backward()\n",
    "            \n",
    "            run[0] += 1\n",
    "            if run[0] % 50 == 0:\n",
    "                print(\"run {}:\".format(run))\n",
    "                print('Style Loss : {:4f} Content Loss: {:4f}'.format(\n",
    "                    style_score.item(), content_score.item()))\n",
    "                print()\n",
    "            \n",
    "            return style_score + content_score\n",
    "        \n",
    "        optimizer.step(closure)\n",
    "    \n",
    "    # 最后修正\n",
    "    input_img.data.clamp_(0, 1)\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib .pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Root = \"./data\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root = Root, train = True, download = True,\n",
    "                  transform = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.1307,), (0.3081,))\n",
    "                  ])), batch_size = 64, shuffle = True, num_workers = 0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root = Root, train = False,\n",
    "                  transform = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.1307,), (0.3081,))\n",
    "                  ])), batch_size = 64, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "        # STN\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size = 7),\n",
    "            nn.MaxPool2d(2, stride = 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size = 5),\n",
    "            nn.MaxPool2d(2, stride = 2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # θ：3×2\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "        \n",
    "        # 初始化\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0],\n",
    "                                                    dtype=torch.float))\n",
    "        \n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        \n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training = self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print(\"Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, size_average = False).item()\n",
    "            pred = output.max(1, keepdim = True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            # eq(): 遍历\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\Bling\\lib\\site-packages\\torch\\nn\\functional.py:3447: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "E:\\Anaconda\\envs\\Bling\\lib\\site-packages\\torch\\nn\\functional.py:3384: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 [0/60000 (0%)]\tLoss: 2.295474\n",
      "Train epoch: 1 [32000/60000 (53%)]\tLoss: 0.731098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\Bling\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2290, Accuracy: 9363/10000 (94%)\n",
      "\n",
      "Train epoch: 2 [0/60000 (0%)]\tLoss: 0.553593\n",
      "Train epoch: 2 [32000/60000 (53%)]\tLoss: 0.444618\n",
      "\n",
      "Test set: Average loss: 0.1330, Accuracy: 9595/10000 (96%)\n",
      "\n",
      "Train epoch: 3 [0/60000 (0%)]\tLoss: 0.136495\n",
      "Train epoch: 3 [32000/60000 (53%)]\tLoss: 0.384323\n",
      "\n",
      "Test set: Average loss: 0.1236, Accuracy: 9607/10000 (96%)\n",
      "\n",
      "Train epoch: 4 [0/60000 (0%)]\tLoss: 0.299150\n",
      "Train epoch: 4 [32000/60000 (53%)]\tLoss: 0.333898\n",
      "\n",
      "Test set: Average loss: 0.0954, Accuracy: 9704/10000 (97%)\n",
      "\n",
      "Train epoch: 5 [0/60000 (0%)]\tLoss: 0.116016\n",
      "Train epoch: 5 [32000/60000 (53%)]\tLoss: 0.311343\n",
      "\n",
      "Test set: Average loss: 0.0807, Accuracy: 9742/10000 (97%)\n",
      "\n",
      "Train epoch: 6 [0/60000 (0%)]\tLoss: 0.200320\n",
      "Train epoch: 6 [32000/60000 (53%)]\tLoss: 0.099090\n",
      "\n",
      "Test set: Average loss: 0.0783, Accuracy: 9747/10000 (97%)\n",
      "\n",
      "Train epoch: 7 [0/60000 (0%)]\tLoss: 0.337202\n",
      "Train epoch: 7 [32000/60000 (53%)]\tLoss: 0.091792\n",
      "\n",
      "Test set: Average loss: 0.0699, Accuracy: 9773/10000 (98%)\n",
      "\n",
      "Train epoch: 8 [0/60000 (0%)]\tLoss: 0.328813\n",
      "Train epoch: 8 [32000/60000 (53%)]\tLoss: 0.064052\n",
      "\n",
      "Test set: Average loss: 0.0589, Accuracy: 9814/10000 (98%)\n",
      "\n",
      "Train epoch: 9 [0/60000 (0%)]\tLoss: 0.198718\n",
      "Train epoch: 9 [32000/60000 (53%)]\tLoss: 0.168681\n",
      "\n",
      "Test set: Average loss: 0.0759, Accuracy: 9768/10000 (98%)\n",
      "\n",
      "Train epoch: 10 [0/60000 (0%)]\tLoss: 0.095374\n",
      "Train epoch: 10 [32000/60000 (53%)]\tLoss: 0.159187\n",
      "\n",
      "Test set: Average loss: 0.0950, Accuracy: 9703/10000 (97%)\n",
      "\n",
      "Train epoch: 11 [0/60000 (0%)]\tLoss: 0.144113\n",
      "Train epoch: 11 [32000/60000 (53%)]\tLoss: 0.115364\n",
      "\n",
      "Test set: Average loss: 0.0987, Accuracy: 9701/10000 (97%)\n",
      "\n",
      "Train epoch: 12 [0/60000 (0%)]\tLoss: 0.146132\n",
      "Train epoch: 12 [32000/60000 (53%)]\tLoss: 0.046033\n",
      "\n",
      "Test set: Average loss: 0.0509, Accuracy: 9849/10000 (98%)\n",
      "\n",
      "Train epoch: 13 [0/60000 (0%)]\tLoss: 0.040668\n",
      "Train epoch: 13 [32000/60000 (53%)]\tLoss: 0.055521\n",
      "\n",
      "Test set: Average loss: 0.0553, Accuracy: 9820/10000 (98%)\n",
      "\n",
      "Train epoch: 14 [0/60000 (0%)]\tLoss: 0.149176\n",
      "Train epoch: 14 [32000/60000 (53%)]\tLoss: 0.113975\n",
      "\n",
      "Test set: Average loss: 0.0815, Accuracy: 9779/10000 (98%)\n",
      "\n",
      "Train epoch: 15 [0/60000 (0%)]\tLoss: 0.054960\n",
      "Train epoch: 15 [32000/60000 (53%)]\tLoss: 0.050403\n",
      "\n",
      "Test set: Average loss: 0.0542, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Train epoch: 16 [0/60000 (0%)]\tLoss: 0.075118\n",
      "Train epoch: 16 [32000/60000 (53%)]\tLoss: 0.024115\n",
      "\n",
      "Test set: Average loss: 0.0693, Accuracy: 9774/10000 (98%)\n",
      "\n",
      "Train epoch: 17 [0/60000 (0%)]\tLoss: 0.169468\n",
      "Train epoch: 17 [32000/60000 (53%)]\tLoss: 0.118563\n",
      "\n",
      "Test set: Average loss: 0.0803, Accuracy: 9781/10000 (98%)\n",
      "\n",
      "Train epoch: 18 [0/60000 (0%)]\tLoss: 0.122203\n",
      "Train epoch: 18 [32000/60000 (53%)]\tLoss: 0.006464\n",
      "\n",
      "Test set: Average loss: 0.0488, Accuracy: 9849/10000 (98%)\n",
      "\n",
      "Train epoch: 19 [0/60000 (0%)]\tLoss: 0.053403\n",
      "Train epoch: 19 [32000/60000 (53%)]\tLoss: 0.039496\n",
      "\n",
      "Test set: Average loss: 0.0487, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "Train epoch: 20 [0/60000 (0%)]\tLoss: 0.016025\n",
      "Train epoch: 20 [32000/60000 (53%)]\tLoss: 0.075044\n",
      "\n",
      "Test set: Average loss: 0.0461, Accuracy: 9868/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 21):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化 STN 结果\n",
    "def convert_image_np(inp):\n",
    "\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    inp = std*inp +mean\n",
    "\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "# STN 可视化一批输入图像和相应变换批次\n",
    "\n",
    "def visualize_stn():\n",
    "    with torch.no_grad():\n",
    "        data = next(iter(test_loader))[0].to(device)\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.stn(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot the results side-by_side\n",
    "        f, axarr= plt.subplots(1,2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title(\"Dataset Images\")\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title(\"Transformed Images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_stn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
