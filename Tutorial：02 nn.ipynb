{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch神经网络\n",
    "  \n",
    "一个典型的神经网络训练过程包括以下几点：  \n",
    "1.定义一个包含可训练参数的神经网络  \n",
    "2.迭代整个输入  \n",
    "3.通过神经网络处理输入  \n",
    "4.计算损失(loss)  \n",
    "5.反向传播梯度到神经网络的参数  \n",
    "6.更新网络的参数，典型的用一个简单的更新方法：weight = weight - learning_rate *gradient  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # torch.nn.Linear（in_features，out_features，bias = True ）\n",
    "        # 输入为[batch_size, in_features]的张量变换成了[batch_size, out_features]的输出张量\n",
    "        # https://blog.csdn.net/qq_42079689/article/details/102873766\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x)) # 变成二维的\n",
    "        print(x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.定义一个神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-0.1349,  0.1467,  0.1184, -0.0255,  0.0521],\n",
      "          [ 0.1381, -0.1011, -0.0850, -0.0293, -0.0547],\n",
      "          [ 0.2000,  0.0971,  0.0777,  0.0252,  0.1191],\n",
      "          [-0.1058,  0.0364,  0.0198, -0.0917, -0.0028],\n",
      "          [-0.0229,  0.0083, -0.1244, -0.1101, -0.0546]]],\n",
      "\n",
      "\n",
      "        [[[-0.1025,  0.0980,  0.1687, -0.1677, -0.0193],\n",
      "          [-0.1645,  0.0033, -0.1953,  0.1175, -0.0983],\n",
      "          [ 0.1003, -0.0635,  0.0410, -0.1394, -0.0530],\n",
      "          [ 0.0878,  0.0984, -0.1403,  0.0196,  0.0905],\n",
      "          [-0.1773,  0.0294,  0.0782,  0.0754, -0.0497]]],\n",
      "\n",
      "\n",
      "        [[[-0.0563,  0.1161, -0.0245, -0.1300,  0.0774],\n",
      "          [ 0.1658,  0.0431, -0.0231, -0.0575, -0.0158],\n",
      "          [ 0.1284, -0.1402,  0.1414,  0.0412, -0.1003],\n",
      "          [ 0.0346, -0.0797, -0.0516, -0.0537, -0.0405],\n",
      "          [ 0.0761, -0.0554,  0.1701, -0.0086, -0.0913]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1607, -0.1700, -0.0649,  0.1922,  0.0293],\n",
      "          [-0.1091,  0.0923, -0.0765,  0.0903,  0.0711],\n",
      "          [ 0.0467,  0.1521,  0.0488,  0.0536,  0.1526],\n",
      "          [ 0.1996, -0.0194, -0.1462, -0.1144,  0.1966],\n",
      "          [-0.1274,  0.1431, -0.0947, -0.0137,  0.1396]]],\n",
      "\n",
      "\n",
      "        [[[-0.0139,  0.0622, -0.1064, -0.1052, -0.0399],\n",
      "          [-0.0809,  0.1370,  0.0833, -0.0476, -0.1546],\n",
      "          [ 0.0758,  0.1559, -0.1182,  0.0500,  0.0542],\n",
      "          [-0.1031,  0.0215, -0.1440, -0.0374,  0.1073],\n",
      "          [ 0.1697, -0.0392, -0.1439, -0.1161,  0.0837]]],\n",
      "\n",
      "\n",
      "        [[[-0.0154,  0.1606, -0.1786, -0.1656, -0.0270],\n",
      "          [-0.1287,  0.1291,  0.1456,  0.1122,  0.0654],\n",
      "          [-0.1214, -0.1631, -0.1466,  0.1745, -0.1544],\n",
      "          [-0.0197, -0.1710, -0.1949,  0.0086, -0.0092],\n",
      "          [-0.1664,  0.1990,  0.0102, -0.0978,  0.1330]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1625, -0.0549, -0.0373,  0.0539,  0.0471, -0.0550],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 6.5921e-02, -6.0822e-02, -1.8527e-02, -6.9932e-02,  7.8889e-02],\n",
      "          [ 6.4960e-02, -7.3184e-02,  7.2655e-02, -5.6513e-05, -3.7017e-02],\n",
      "          [ 9.0869e-03,  1.2700e-02,  6.9826e-03, -1.6189e-02,  4.4162e-02],\n",
      "          [ 5.8216e-02,  2.4050e-02, -5.6126e-02, -7.3647e-02, -7.9976e-02],\n",
      "          [ 6.7844e-02,  6.3144e-02,  4.7329e-02, -2.4356e-02, -8.1511e-02]],\n",
      "\n",
      "         [[ 5.7367e-02,  5.8953e-02,  5.8781e-02, -5.3902e-02, -1.7150e-02],\n",
      "          [ 3.5843e-02,  3.6535e-02, -2.7602e-02, -5.8505e-02, -4.9139e-02],\n",
      "          [ 5.6714e-02,  4.8740e-02, -7.4933e-02, -9.0525e-03,  7.1584e-02],\n",
      "          [-7.7093e-03,  6.1582e-02,  5.0242e-02,  2.4705e-03,  1.4268e-05],\n",
      "          [-2.2651e-02, -1.3986e-02,  7.8663e-02,  5.9720e-02, -6.0587e-02]],\n",
      "\n",
      "         [[ 5.9356e-02, -3.7598e-04,  5.4841e-02,  2.5810e-02,  6.9778e-02],\n",
      "          [-1.0393e-02,  3.2963e-02,  2.3378e-02,  4.3547e-02, -3.8357e-02],\n",
      "          [-6.7222e-02, -3.6217e-02, -2.7195e-02, -1.2725e-02, -4.6748e-03],\n",
      "          [-1.7848e-02,  4.8546e-03,  5.7075e-02, -2.6780e-02, -7.1658e-02],\n",
      "          [ 1.7285e-02, -2.2785e-02,  4.2297e-02, -4.3246e-02,  5.9783e-02]],\n",
      "\n",
      "         [[ 7.1974e-02,  2.5027e-02,  7.6944e-02, -4.2862e-02,  5.7622e-02],\n",
      "          [-8.5173e-03, -3.9733e-02, -6.3524e-02,  4.7805e-02, -6.6917e-02],\n",
      "          [-1.2910e-02,  7.0427e-03, -1.9545e-02,  4.9709e-02, -2.1184e-02],\n",
      "          [-1.6933e-02, -6.8413e-02, -5.3321e-02, -4.3787e-02, -7.7759e-02],\n",
      "          [ 1.9235e-02, -6.0095e-02, -5.7382e-02, -3.1194e-03, -7.3850e-02]],\n",
      "\n",
      "         [[ 2.5148e-02, -4.0269e-02,  6.3676e-02, -6.6778e-02,  6.4151e-02],\n",
      "          [-2.4607e-02,  1.6493e-02, -8.1517e-02,  3.6211e-02,  6.9524e-02],\n",
      "          [ 5.7098e-02, -2.1325e-02, -5.8990e-02,  6.5250e-02,  5.4638e-02],\n",
      "          [-7.3287e-02,  3.4113e-02,  1.6163e-02,  6.0429e-02,  5.8949e-02],\n",
      "          [ 2.0267e-02,  3.3179e-02, -3.3854e-03,  7.5984e-02,  5.8621e-02]],\n",
      "\n",
      "         [[-3.0512e-02, -4.7559e-02, -2.4700e-02, -2.4995e-02,  6.7831e-03],\n",
      "          [ 6.4592e-02, -4.7131e-02, -6.8327e-02,  7.9697e-02, -2.4853e-02],\n",
      "          [ 1.9851e-02, -7.3769e-02, -7.1481e-02, -4.9042e-02, -3.7300e-02],\n",
      "          [ 1.0323e-02,  3.9629e-02, -7.2578e-02,  4.7495e-02, -4.1422e-02],\n",
      "          [-4.1838e-02, -3.7751e-02, -2.9472e-02, -4.7720e-03,  5.2748e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8799e-03,  6.1217e-02,  7.4360e-03, -3.5552e-02, -4.8810e-02],\n",
      "          [ 8.8491e-04,  2.1031e-02,  5.6014e-02, -5.1417e-02,  3.7507e-02],\n",
      "          [ 3.9722e-02,  1.9834e-02,  7.5005e-02, -2.2698e-02, -5.0462e-02],\n",
      "          [-1.9872e-02, -2.6473e-02,  3.0907e-02, -2.6739e-02,  2.2057e-02],\n",
      "          [-7.1784e-02, -1.9896e-02,  1.9148e-02, -1.1995e-02, -1.0353e-02]],\n",
      "\n",
      "         [[ 4.0394e-02, -4.3372e-02, -1.3849e-02, -5.2814e-02, -5.3779e-02],\n",
      "          [-4.8563e-02,  4.2429e-02, -1.5385e-02, -6.5028e-03, -2.1066e-02],\n",
      "          [ 5.5091e-02, -1.0030e-02,  3.7717e-02,  2.1090e-02, -4.8521e-02],\n",
      "          [ 3.7880e-02,  7.2136e-02,  7.6458e-02,  7.9244e-02, -5.2182e-02],\n",
      "          [-3.5430e-02,  6.9405e-04, -4.4364e-02, -3.5400e-02,  6.8056e-02]],\n",
      "\n",
      "         [[-5.9585e-02, -5.6721e-02,  8.0137e-02,  5.0558e-02,  6.1310e-02],\n",
      "          [-2.9774e-03, -6.6284e-02, -3.7693e-02, -5.0938e-02, -2.0430e-02],\n",
      "          [-1.4818e-02,  3.9354e-02,  2.7685e-02,  6.5350e-02, -5.3493e-03],\n",
      "          [-9.2145e-03, -1.9700e-02,  6.6503e-02,  6.1733e-02,  1.1479e-02],\n",
      "          [-2.7163e-02,  6.3253e-03, -5.9553e-03, -7.4118e-02, -1.6850e-02]],\n",
      "\n",
      "         [[-2.3703e-02,  6.7801e-02, -6.5104e-02, -6.1763e-03, -5.6772e-02],\n",
      "          [-4.3117e-02,  4.4925e-02, -3.4847e-02,  2.9658e-02, -5.1434e-02],\n",
      "          [ 3.2282e-02,  2.1509e-02, -4.5341e-02, -4.4229e-02, -6.6098e-02],\n",
      "          [ 7.5166e-02, -3.4283e-02, -1.6371e-02,  5.2200e-02, -6.2562e-02],\n",
      "          [ 1.7171e-02,  8.4999e-03,  3.7766e-02, -5.1578e-02, -5.9816e-02]],\n",
      "\n",
      "         [[-9.5632e-03, -1.6836e-02, -7.3568e-02, -7.2474e-02,  6.8660e-02],\n",
      "          [-4.5282e-02,  3.3479e-02,  8.2148e-04, -2.0099e-02, -1.6957e-02],\n",
      "          [ 6.1415e-02,  2.9648e-02, -3.4820e-02, -4.3442e-02, -1.0297e-02],\n",
      "          [-5.7420e-02,  7.0769e-02,  7.7372e-02,  5.9594e-02,  6.5133e-02],\n",
      "          [ 7.5181e-03,  3.2127e-02,  4.2813e-03,  7.0077e-02, -3.9360e-02]],\n",
      "\n",
      "         [[ 7.1475e-02,  2.7117e-02, -2.2839e-02, -4.2105e-02,  1.3381e-02],\n",
      "          [ 6.8594e-02, -3.0123e-02,  5.2183e-02,  2.6767e-02,  7.0021e-02],\n",
      "          [-2.5878e-02,  5.9898e-02, -1.1252e-02, -6.6412e-02,  4.7925e-02],\n",
      "          [-4.4307e-03,  4.7792e-02,  4.1142e-02, -2.6952e-02,  7.1387e-02],\n",
      "          [-4.4418e-02,  7.1442e-03, -8.4012e-03,  6.3878e-02,  7.2719e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9424e-02,  2.6870e-02, -2.6691e-02,  7.9860e-02, -3.3204e-02],\n",
      "          [-7.8003e-02, -7.7109e-02, -7.8798e-02,  2.8093e-02,  2.0353e-02],\n",
      "          [ 7.8287e-02,  7.1884e-02, -5.8474e-02, -2.6173e-02,  5.5319e-02],\n",
      "          [ 1.1836e-02, -7.6992e-02, -2.6588e-03, -5.9429e-02, -6.6951e-02],\n",
      "          [-3.1761e-03,  1.5862e-02,  5.5885e-02, -1.4267e-02,  3.1824e-02]],\n",
      "\n",
      "         [[ 1.8358e-02,  6.0600e-02, -1.3641e-02, -1.9804e-02,  5.1557e-03],\n",
      "          [-6.3428e-02, -5.4028e-02,  4.4619e-02,  1.5942e-02,  1.1119e-02],\n",
      "          [ 4.8915e-02, -5.5453e-02, -6.9555e-02, -7.2909e-02, -1.7826e-02],\n",
      "          [ 6.6974e-02,  3.4076e-02,  1.0755e-02, -4.2725e-02, -2.2379e-02],\n",
      "          [-7.4956e-02, -7.8345e-02,  2.3511e-02,  6.4818e-02,  4.3903e-02]],\n",
      "\n",
      "         [[ 1.5922e-02,  4.4793e-03,  6.2725e-02, -6.0811e-02,  8.1608e-02],\n",
      "          [ 6.9865e-02, -3.3149e-02,  4.7615e-02,  3.3790e-02,  7.8756e-02],\n",
      "          [ 6.7175e-03,  2.6374e-03,  3.1350e-02,  1.5626e-02,  1.0683e-02],\n",
      "          [-4.8656e-02, -3.5913e-02, -6.1827e-02,  4.6390e-02,  7.1337e-02],\n",
      "          [ 4.7145e-02, -2.1117e-02,  5.3321e-02, -4.8982e-02, -5.8175e-02]],\n",
      "\n",
      "         [[ 2.2084e-02,  6.8855e-02,  2.2055e-02,  3.1122e-02,  4.8175e-03],\n",
      "          [ 5.2428e-02,  5.3097e-02,  1.1849e-02, -7.1110e-02,  4.3736e-02],\n",
      "          [ 7.1103e-02,  1.0259e-02, -3.1287e-03,  5.5935e-02, -4.8876e-02],\n",
      "          [ 2.5908e-02,  7.9682e-02, -2.7520e-02, -4.1850e-03, -1.1266e-02],\n",
      "          [-3.1748e-02, -7.1867e-02, -3.4560e-02,  2.7538e-03,  7.3103e-02]],\n",
      "\n",
      "         [[-7.9010e-02, -5.6168e-02,  7.9837e-02,  2.4687e-02, -3.4086e-02],\n",
      "          [ 3.7777e-03, -2.3168e-02, -2.7657e-02, -1.0861e-02,  1.0101e-02],\n",
      "          [-7.3901e-02, -5.8045e-02, -5.4216e-03, -4.4921e-02, -5.9061e-02],\n",
      "          [-4.9476e-02,  7.1744e-02,  7.5238e-02,  1.6769e-02,  6.9527e-02],\n",
      "          [ 6.0943e-02,  3.4522e-02,  7.9957e-02,  4.4258e-02,  1.1843e-02]],\n",
      "\n",
      "         [[-1.4889e-02,  1.3774e-02,  6.6214e-02, -7.1921e-02,  1.6126e-02],\n",
      "          [-7.4108e-02,  7.4726e-02, -2.0480e-02,  6.5972e-02, -8.2332e-03],\n",
      "          [-3.9473e-02,  6.2191e-02, -4.1817e-02,  4.4139e-02,  5.1281e-02],\n",
      "          [ 2.2706e-02,  7.6021e-02,  5.0548e-02,  1.7314e-02, -1.1356e-02],\n",
      "          [ 7.4297e-02, -5.4185e-02,  1.9487e-02, -4.0425e-02, -3.6382e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.1380e-02, -1.1579e-02,  3.5519e-02, -6.5993e-02,  4.1059e-02],\n",
      "          [-6.0277e-02, -5.0359e-02,  1.3242e-02,  4.3177e-02, -3.7118e-02],\n",
      "          [ 2.0777e-02, -2.3483e-03, -4.4730e-03, -7.0157e-02,  2.0247e-02],\n",
      "          [ 2.6722e-02, -7.9256e-02,  2.2029e-02,  4.0853e-02,  3.4158e-02],\n",
      "          [-1.9451e-02,  5.3374e-02,  4.1389e-02, -3.7019e-02, -2.7918e-02]],\n",
      "\n",
      "         [[ 8.1514e-02,  4.2113e-02, -3.7656e-02,  3.7903e-02, -5.0472e-02],\n",
      "          [-1.3400e-02,  6.2463e-02,  1.5048e-02,  3.7876e-02,  1.6376e-02],\n",
      "          [ 3.1305e-02,  8.2808e-03, -2.8877e-02, -4.2482e-02, -2.6401e-02],\n",
      "          [-3.1838e-02,  5.1746e-02,  6.9572e-02, -4.9077e-02,  7.3719e-02],\n",
      "          [-1.3438e-02,  6.3967e-02,  4.1643e-02, -4.8053e-02, -6.4062e-02]],\n",
      "\n",
      "         [[ 3.5947e-02, -5.3516e-02,  2.2334e-02, -2.8032e-02, -7.2651e-02],\n",
      "          [-7.3762e-02, -7.1719e-02, -5.5366e-02, -1.6787e-02,  5.1233e-02],\n",
      "          [ 5.9484e-02,  4.8484e-02, -3.4264e-02, -2.9299e-02,  1.4011e-02],\n",
      "          [-6.4263e-02, -1.9058e-02,  4.2414e-02, -1.9017e-02, -5.3004e-02],\n",
      "          [-2.5412e-02,  4.4725e-02,  3.0094e-02,  3.4110e-02, -1.7352e-02]],\n",
      "\n",
      "         [[-6.9701e-02,  4.6911e-02, -7.2971e-02,  7.4562e-02,  2.5031e-02],\n",
      "          [-6.7421e-02, -5.1990e-04, -5.9506e-02,  2.5007e-02,  6.5428e-02],\n",
      "          [-2.0767e-02,  6.4475e-02, -7.8635e-03,  4.2641e-02, -7.5194e-02],\n",
      "          [ 2.8017e-02,  2.1439e-02,  4.2216e-02,  7.9855e-02,  4.7495e-02],\n",
      "          [ 2.1594e-02,  5.2888e-02, -2.2024e-02, -4.3556e-02, -6.5952e-02]],\n",
      "\n",
      "         [[ 6.3493e-02,  4.3029e-02,  3.8254e-02, -6.0174e-02,  3.9729e-02],\n",
      "          [ 8.0184e-02, -3.4582e-02,  8.1580e-02, -6.3639e-02, -7.4506e-03],\n",
      "          [ 3.3214e-02, -1.4651e-02, -6.6733e-02,  7.2620e-02,  4.6727e-02],\n",
      "          [-5.7450e-02, -2.4565e-02, -2.3632e-02,  7.2433e-02,  8.0933e-02],\n",
      "          [-5.4247e-03, -6.5798e-02,  5.6784e-02,  1.8899e-03, -4.6480e-02]],\n",
      "\n",
      "         [[ 7.5721e-02, -6.5564e-02, -1.8061e-02,  3.8318e-02, -1.0013e-02],\n",
      "          [-6.8040e-02,  4.9628e-02,  7.0008e-02,  7.7428e-02, -6.2413e-02],\n",
      "          [ 5.1803e-02, -4.0757e-03,  1.1847e-03,  6.9004e-02, -5.3631e-02],\n",
      "          [-1.0954e-02, -6.5985e-02, -4.9320e-03, -5.2504e-02,  2.8104e-02],\n",
      "          [ 4.7617e-03,  6.0973e-02, -6.3833e-02, -5.8880e-02,  8.1586e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2274e-02,  1.2279e-02,  4.3776e-02, -2.0339e-02, -2.8039e-02],\n",
      "          [ 5.7549e-02, -7.0003e-02,  7.8135e-02,  7.5780e-02,  4.9830e-02],\n",
      "          [ 3.8846e-02,  7.1142e-02, -8.2899e-03, -4.9419e-02,  5.3931e-03],\n",
      "          [ 5.8617e-02,  4.2457e-03,  2.4673e-03,  1.3985e-02,  7.2440e-02],\n",
      "          [ 7.9953e-03, -9.0531e-03,  4.3574e-02, -5.7996e-02, -7.9607e-02]],\n",
      "\n",
      "         [[-3.3042e-02,  2.0620e-02,  7.1083e-02, -3.6745e-02, -1.7096e-02],\n",
      "          [ 1.0511e-02, -1.7806e-02, -4.7665e-04,  5.9473e-02, -3.4415e-02],\n",
      "          [-6.3019e-02,  3.3662e-02,  2.9256e-02, -4.4795e-02, -8.0615e-02],\n",
      "          [ 4.5664e-02,  3.0881e-02, -1.9711e-02, -2.5482e-02,  2.6897e-02],\n",
      "          [-2.1085e-02,  5.1711e-02, -1.3189e-02,  2.0885e-02, -3.2141e-02]],\n",
      "\n",
      "         [[-4.1259e-02,  5.0189e-02,  1.1037e-02,  3.8866e-02, -3.8678e-02],\n",
      "          [ 1.6824e-03,  6.7408e-02, -2.2454e-02,  7.5978e-02, -7.0082e-03],\n",
      "          [ 7.0103e-02, -3.4681e-02,  3.5210e-02,  1.6385e-03, -1.9487e-02],\n",
      "          [-2.0572e-02, -7.3543e-02, -6.1916e-02, -3.9613e-02,  5.1032e-02],\n",
      "          [-5.3157e-03, -7.8518e-03,  6.5548e-02, -4.6084e-02, -1.0082e-02]],\n",
      "\n",
      "         [[-5.1095e-02,  7.9738e-02,  5.3519e-02,  4.6358e-02,  6.8904e-02],\n",
      "          [ 5.3704e-02,  4.4217e-02,  7.4154e-02,  3.7061e-02,  2.1394e-02],\n",
      "          [ 5.2201e-03,  7.6225e-02, -1.0820e-04,  8.6381e-03,  2.7760e-03],\n",
      "          [-1.1401e-02, -2.2068e-02, -8.0160e-02,  2.8152e-02,  6.4580e-02],\n",
      "          [ 6.4742e-03, -5.8938e-02,  2.9907e-02,  6.1887e-02, -3.1793e-02]],\n",
      "\n",
      "         [[ 7.6546e-02,  6.5411e-02, -6.2700e-02, -7.2718e-02,  5.7198e-02],\n",
      "          [-2.3992e-02,  3.5429e-02,  5.7513e-02,  3.5435e-02, -3.2613e-02],\n",
      "          [-2.4677e-02,  6.8953e-02, -2.9874e-02,  8.5700e-03,  3.0758e-02],\n",
      "          [ 7.5710e-02,  1.7216e-03, -7.4464e-02, -6.4887e-02,  1.2437e-02],\n",
      "          [-3.7212e-02, -7.4397e-02,  7.7550e-02, -3.0282e-02,  5.9138e-02]],\n",
      "\n",
      "         [[ 3.0883e-02, -8.0426e-02, -4.0668e-02,  7.3441e-02, -5.8606e-02],\n",
      "          [-1.7132e-02, -6.5447e-02,  5.9308e-02, -6.7826e-02,  8.1216e-02],\n",
      "          [-3.4359e-02,  8.0382e-02,  3.3172e-02, -7.0656e-02, -5.0787e-02],\n",
      "          [ 5.1931e-02,  5.9312e-02, -5.4288e-02, -3.9134e-02, -2.5326e-02],\n",
      "          [-5.2672e-02, -1.1790e-02,  4.0989e-02,  5.8162e-02, -5.7964e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.8100e-02,  4.1475e-02, -2.4096e-02, -3.7204e-02, -2.1026e-02],\n",
      "          [ 6.2123e-02,  3.4464e-02,  2.8501e-04, -2.7095e-02,  4.9577e-02],\n",
      "          [-6.0346e-03,  3.7981e-02,  2.1440e-02,  7.4612e-02,  5.1544e-02],\n",
      "          [ 4.4657e-02,  1.8545e-02,  6.0164e-02, -4.4654e-02,  6.9663e-02],\n",
      "          [ 7.6009e-02, -1.8066e-02,  8.3186e-04, -7.9897e-03,  8.9995e-03]],\n",
      "\n",
      "         [[-2.0312e-02, -6.4492e-02,  5.5157e-03,  5.5651e-02,  4.8586e-02],\n",
      "          [-2.8445e-02, -7.9300e-02, -8.0573e-02, -1.0283e-03, -7.7620e-02],\n",
      "          [ 2.6856e-02, -1.6338e-02, -4.7393e-02,  7.5645e-02,  4.1779e-02],\n",
      "          [-1.9853e-02, -7.6790e-02,  2.8048e-02,  2.5764e-03, -8.0510e-02],\n",
      "          [-6.0713e-02,  5.5347e-02, -6.0089e-03,  3.0854e-02,  2.8619e-02]],\n",
      "\n",
      "         [[-6.0572e-02,  2.8299e-02, -5.4135e-02,  5.2051e-02, -3.1993e-02],\n",
      "          [ 6.4855e-02, -1.1518e-02,  2.5610e-02,  5.6879e-02, -3.0941e-02],\n",
      "          [-7.5480e-02,  4.0565e-02,  4.9660e-02, -5.3476e-02,  1.3038e-02],\n",
      "          [-8.8499e-04,  2.8573e-02,  5.8074e-02,  8.0075e-02,  2.8685e-02],\n",
      "          [ 3.4028e-02,  7.4819e-02, -4.0671e-02, -4.9422e-02, -4.2130e-02]],\n",
      "\n",
      "         [[-8.1119e-02,  1.6858e-02,  7.0587e-02, -3.2011e-02, -1.4571e-02],\n",
      "          [ 5.5711e-02, -6.7700e-02,  4.8681e-02, -4.6567e-02,  3.8612e-02],\n",
      "          [-2.0590e-03,  3.6371e-02, -6.3197e-02,  2.6848e-02,  3.1605e-02],\n",
      "          [-4.7552e-02, -4.3531e-02, -5.7824e-02, -1.9886e-03, -4.6362e-02],\n",
      "          [ 5.3633e-03,  6.5134e-02,  2.1131e-02,  3.3749e-02, -7.0893e-02]],\n",
      "\n",
      "         [[-1.8361e-02, -4.0586e-02,  5.0120e-02, -7.0731e-02,  2.7279e-02],\n",
      "          [-6.0783e-02, -4.9537e-02, -1.2100e-03,  7.9041e-02,  4.3914e-02],\n",
      "          [-1.3926e-02, -6.3633e-02,  6.8255e-02, -5.4073e-02,  1.2968e-02],\n",
      "          [ 4.2495e-02,  5.2322e-02,  2.9355e-02, -2.3234e-02, -1.4101e-02],\n",
      "          [-7.6982e-02,  2.4020e-02,  3.5059e-02,  7.7630e-02, -3.7221e-03]],\n",
      "\n",
      "         [[ 6.0912e-02, -3.3686e-02, -1.9329e-02,  1.1437e-03,  8.8745e-04],\n",
      "          [ 3.0662e-02, -1.6266e-02,  6.8519e-02, -2.5063e-02,  6.4024e-02],\n",
      "          [ 6.6546e-02, -2.0393e-02, -1.5172e-02,  2.6297e-02, -8.1316e-02],\n",
      "          [-8.7709e-03,  1.4967e-02, -3.1136e-02, -7.6213e-02, -5.3340e-02],\n",
      "          [-7.1399e-02,  4.0546e-03,  7.1668e-02,  7.9246e-02,  1.8528e-02]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0586, -0.0040, -0.0078,  0.0364, -0.0298, -0.0570,  0.0483, -0.0333,\n",
      "         0.0432, -0.0777,  0.0170, -0.0240,  0.0401,  0.0471, -0.0602,  0.0313],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0177, -0.0467, -0.0177,  ..., -0.0223, -0.0337, -0.0081],\n",
      "        [ 0.0089,  0.0270, -0.0074,  ...,  0.0226, -0.0385,  0.0254],\n",
      "        [-0.0413,  0.0053,  0.0342,  ..., -0.0022, -0.0450,  0.0359],\n",
      "        ...,\n",
      "        [-0.0167,  0.0462, -0.0210,  ...,  0.0142, -0.0269, -0.0021],\n",
      "        [ 0.0043,  0.0312, -0.0497,  ...,  0.0260, -0.0208,  0.0077],\n",
      "        [-0.0463, -0.0279,  0.0028,  ..., -0.0480, -0.0013, -0.0109]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 6.6325e-03,  4.4537e-02,  5.8510e-03, -1.9090e-02,  4.0281e-02,\n",
      "         1.3195e-04, -1.9028e-02,  1.8681e-03,  2.8071e-02, -2.9590e-02,\n",
      "         1.5501e-02,  2.6966e-02,  1.8173e-02, -3.3922e-02,  2.1069e-02,\n",
      "        -9.2865e-03,  2.5217e-02,  4.8924e-02,  2.3958e-02,  1.4194e-02,\n",
      "        -4.3958e-02, -3.6572e-02, -4.9305e-02, -1.1185e-02,  3.6460e-02,\n",
      "         3.6593e-02, -2.3474e-02,  3.5994e-02,  2.8711e-02, -1.6189e-02,\n",
      "         3.3892e-02, -2.8172e-02,  2.8430e-02, -1.7949e-02,  2.6084e-02,\n",
      "        -3.7637e-02,  1.8022e-02, -4.3392e-02, -3.0646e-02, -3.9809e-02,\n",
      "         7.2052e-03,  2.7445e-02,  1.3814e-02,  5.8894e-03, -2.4865e-02,\n",
      "        -2.3183e-02, -1.6351e-03, -7.8696e-03, -7.7145e-03, -4.2481e-02,\n",
      "         4.2928e-02, -3.1849e-02, -2.7747e-02, -2.8703e-02,  4.5860e-02,\n",
      "        -3.9875e-02,  3.7888e-02,  1.8682e-02, -4.3124e-02,  2.7571e-02,\n",
      "         4.0370e-02,  4.3370e-02, -4.0879e-02, -2.3275e-02, -2.1579e-02,\n",
      "         1.5728e-02, -9.1273e-03, -3.9577e-02,  1.2774e-02,  1.4755e-02,\n",
      "         2.6415e-02, -3.2375e-02,  4.0807e-02,  1.3107e-02, -3.5282e-02,\n",
      "         9.0361e-05,  3.5325e-02, -3.4784e-02, -5.5235e-04, -4.8058e-02,\n",
      "         8.2390e-03, -4.1220e-02, -1.2367e-02,  3.2460e-02, -2.6594e-02,\n",
      "         4.5057e-02, -3.7839e-02,  6.3062e-03,  4.3494e-02,  2.9755e-02,\n",
      "         4.0487e-02, -4.0745e-02, -3.4273e-02,  3.3685e-02, -3.2226e-02,\n",
      "         6.1494e-03,  3.0519e-02, -2.9345e-02,  3.2919e-02,  3.5929e-02,\n",
      "         1.4708e-02, -1.3913e-02, -4.3269e-02,  4.2538e-02,  3.9919e-03,\n",
      "         3.8099e-02, -2.6607e-02,  4.7915e-03,  4.5361e-02,  3.6505e-02,\n",
      "         1.0625e-02,  2.0401e-02,  5.0872e-04, -1.0413e-02,  1.8524e-02,\n",
      "         1.5585e-02,  3.7610e-02, -1.4006e-02,  4.4812e-02,  1.5281e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0061,  0.0239,  0.0823,  ..., -0.0860, -0.0433,  0.0097],\n",
      "        [-0.0741, -0.0517,  0.0564,  ..., -0.0315, -0.0397,  0.0291],\n",
      "        [-0.0491,  0.0146, -0.0159,  ..., -0.0591,  0.0200, -0.0376],\n",
      "        ...,\n",
      "        [-0.0604,  0.0767,  0.0161,  ...,  0.0700, -0.0366, -0.0139],\n",
      "        [-0.0579,  0.0228,  0.0540,  ..., -0.0232,  0.0693, -0.0342],\n",
      "        [ 0.0595,  0.0667, -0.0125,  ..., -0.0710, -0.0670, -0.0742]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0315,  0.0647,  0.0337,  0.0190,  0.0123, -0.0078,  0.0042,  0.0783,\n",
      "        -0.0731,  0.0128, -0.0368,  0.0051,  0.0234,  0.0229,  0.0430, -0.0598,\n",
      "         0.0331,  0.0722, -0.0360,  0.0037,  0.0143, -0.0513, -0.0593, -0.0731,\n",
      "        -0.0831,  0.0624, -0.0615, -0.0796,  0.0772, -0.0436, -0.0202,  0.0115,\n",
      "        -0.0648,  0.0568, -0.0856,  0.0437, -0.0658, -0.0550,  0.0539, -0.0020,\n",
      "        -0.0747,  0.0302, -0.0310,  0.0237, -0.0146, -0.0254,  0.0037, -0.0828,\n",
      "        -0.0337, -0.0540, -0.0414,  0.0041, -0.0519, -0.0577, -0.0091,  0.0172,\n",
      "         0.0546,  0.0836,  0.0448, -0.0172, -0.0605,  0.0677,  0.0428, -0.0651,\n",
      "        -0.0567, -0.0189,  0.0167, -0.0378, -0.0822, -0.0167,  0.0192, -0.0235,\n",
      "         0.0093, -0.0701, -0.0451, -0.0471,  0.0807, -0.0124,  0.0232,  0.0447,\n",
      "        -0.0508, -0.0904, -0.0147, -0.0790], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0644, -0.0071,  0.0153,  0.0738, -0.0972,  0.0797, -0.0666,  0.0961,\n",
      "         -0.0942,  0.0436, -0.0169, -0.0226,  0.0628, -0.0769,  0.0915,  0.0653,\n",
      "         -0.1047,  0.0199,  0.0060,  0.0767, -0.0652,  0.0134,  0.0408,  0.0202,\n",
      "         -0.0443,  0.0515, -0.0044, -0.0029,  0.0590,  0.0254, -0.0059,  0.0044,\n",
      "          0.0662, -0.0644, -0.0605, -0.0821, -0.0310, -0.0006,  0.0255,  0.0423,\n",
      "         -0.0575, -0.0192, -0.0751, -0.0316, -0.0165, -0.0425, -0.0543, -0.0823,\n",
      "         -0.0351, -0.1047,  0.0903, -0.0498, -0.0596,  0.1048,  0.0697, -0.0417,\n",
      "          0.0152, -0.0372, -0.0305, -0.0487,  0.0240, -0.0821, -0.0372, -0.0431,\n",
      "         -0.0058,  0.0880, -0.0228,  0.0595,  0.0094, -0.0897,  0.0951,  0.0951,\n",
      "         -0.0926, -0.0705, -0.0172, -0.0799,  0.0391, -0.0325, -0.0002, -0.1045,\n",
      "         -0.0592, -0.0731, -0.0723, -0.0047],\n",
      "        [ 0.0287,  0.1005,  0.0514, -0.0184, -0.0231, -0.0459,  0.0392,  0.0835,\n",
      "         -0.0797,  0.0103, -0.0649,  0.0834, -0.0277, -0.0441, -0.0784, -0.0486,\n",
      "         -0.0388,  0.1049,  0.0983, -0.0025,  0.0555,  0.0300, -0.0669,  0.0829,\n",
      "          0.0505,  0.0175,  0.0816,  0.0369, -0.0193, -0.1084, -0.0609,  0.0161,\n",
      "         -0.0506, -0.0259,  0.1078, -0.0988,  0.0285,  0.1017, -0.0568,  0.0866,\n",
      "         -0.1082,  0.0711,  0.0686,  0.0949, -0.0994,  0.0523,  0.0598,  0.0136,\n",
      "         -0.0003, -0.0214, -0.0688, -0.0466, -0.1080, -0.0113, -0.0862, -0.0622,\n",
      "         -0.1030,  0.0214,  0.0949,  0.0579, -0.0349, -0.0986,  0.0990,  0.0094,\n",
      "          0.0848, -0.0850,  0.0150,  0.0260, -0.0590,  0.0324, -0.0531,  0.0237,\n",
      "          0.0285,  0.0222, -0.0880, -0.0150, -0.0040, -0.0615,  0.0584, -0.0861,\n",
      "          0.1038,  0.0822,  0.0423, -0.0069],\n",
      "        [ 0.0384, -0.0382, -0.0607, -0.0660, -0.1049,  0.0065,  0.0055,  0.0896,\n",
      "         -0.0032,  0.0412, -0.0596, -0.0460,  0.0615, -0.0886,  0.0878,  0.0839,\n",
      "         -0.1048,  0.0193, -0.0796, -0.1030,  0.0097,  0.1089,  0.0648,  0.0680,\n",
      "         -0.0031, -0.0996,  0.0353,  0.0786, -0.0863, -0.0347,  0.0162, -0.0801,\n",
      "          0.0317, -0.0547, -0.0580, -0.0599,  0.0202,  0.0800,  0.0121, -0.0092,\n",
      "          0.0995,  0.0961, -0.0826, -0.0924, -0.0403, -0.0207, -0.0987,  0.0087,\n",
      "          0.0493,  0.0559, -0.0270, -0.0756,  0.0695,  0.0151,  0.0618,  0.0632,\n",
      "          0.0251, -0.0020,  0.0739, -0.0055,  0.0527,  0.0056, -0.0353,  0.0924,\n",
      "         -0.0770,  0.0477,  0.0078,  0.0495,  0.0802, -0.1074, -0.0222,  0.0555,\n",
      "         -0.0393,  0.0556, -0.0671,  0.0403,  0.0894, -0.0933,  0.0416,  0.0949,\n",
      "         -0.0830,  0.0980, -0.1007,  0.0994],\n",
      "        [-0.1081,  0.0619,  0.0273, -0.0558,  0.0247,  0.1035,  0.0044,  0.0600,\n",
      "         -0.0321, -0.0012,  0.0235, -0.0042, -0.0110,  0.0403, -0.1090,  0.0929,\n",
      "         -0.0729,  0.0022,  0.0487, -0.0772, -0.0864,  0.0961, -0.0865,  0.0816,\n",
      "          0.0062, -0.1016,  0.0834,  0.0913,  0.1079,  0.0195, -0.0070, -0.0009,\n",
      "         -0.0122, -0.0524,  0.0038,  0.0485,  0.0811,  0.0135, -0.0603, -0.0146,\n",
      "          0.0975, -0.0609,  0.0169,  0.1041, -0.0243,  0.0910, -0.0222, -0.0417,\n",
      "         -0.0802,  0.0709,  0.0553,  0.1008, -0.0358, -0.1070, -0.0653, -0.0781,\n",
      "         -0.0543,  0.0714, -0.0542, -0.0093,  0.0093, -0.0171,  0.0394,  0.0749,\n",
      "          0.0700, -0.0353,  0.0197,  0.0438, -0.0588, -0.0468, -0.0770,  0.0524,\n",
      "          0.1008,  0.0886, -0.0825, -0.0957,  0.0635, -0.0901, -0.0958, -0.0416,\n",
      "          0.0693, -0.1075, -0.0130, -0.0123],\n",
      "        [ 0.0133,  0.1085,  0.0723, -0.0886, -0.0201, -0.0555,  0.0241, -0.0618,\n",
      "          0.0989,  0.0935, -0.0090,  0.0031,  0.0297,  0.0019, -0.0092, -0.0034,\n",
      "         -0.0314,  0.0533, -0.0004, -0.0368, -0.0232, -0.0142, -0.0346,  0.0377,\n",
      "         -0.0487,  0.0346, -0.0027,  0.0038, -0.0974,  0.0498, -0.0717,  0.0009,\n",
      "          0.0025,  0.0142,  0.0093, -0.0261,  0.0003,  0.0306,  0.0240, -0.0646,\n",
      "         -0.0406,  0.1000,  0.0096,  0.0796, -0.0365,  0.0352, -0.0602,  0.0289,\n",
      "          0.0871,  0.0621,  0.0301, -0.0360, -0.0120,  0.0445, -0.0931, -0.0826,\n",
      "          0.0915,  0.0090,  0.0360,  0.0273,  0.0462, -0.0181, -0.0207,  0.0030,\n",
      "          0.1061, -0.0846,  0.0340, -0.0164,  0.0194,  0.0074, -0.1044,  0.0801,\n",
      "          0.0835, -0.0202,  0.0563, -0.0061,  0.1081,  0.0200,  0.0542,  0.1061,\n",
      "          0.0208, -0.0212,  0.0759, -0.0630],\n",
      "        [-0.0436,  0.0669,  0.0572, -0.0834,  0.0509, -0.0035, -0.0498, -0.0427,\n",
      "         -0.0103,  0.0961,  0.0086, -0.0738,  0.0694,  0.0898, -0.0669, -0.0829,\n",
      "         -0.0696,  0.0833,  0.0660,  0.0601,  0.1029,  0.0549,  0.1045,  0.1051,\n",
      "         -0.0592,  0.0741, -0.1078, -0.0076, -0.0073, -0.0575, -0.0117, -0.0466,\n",
      "         -0.0620, -0.0380,  0.0207, -0.0089, -0.0879, -0.0102,  0.0505, -0.0767,\n",
      "         -0.1000, -0.0860,  0.0414,  0.0542, -0.0038,  0.0509,  0.0207,  0.0700,\n",
      "         -0.0052,  0.0344,  0.1045, -0.0781,  0.0885,  0.0333,  0.0326,  0.0896,\n",
      "         -0.0391,  0.0987,  0.0659, -0.0999,  0.0491,  0.0771, -0.0920, -0.0197,\n",
      "         -0.0883,  0.0964, -0.0799,  0.0374,  0.0820, -0.0572,  0.0949, -0.0857,\n",
      "         -0.0319, -0.0047,  0.0906, -0.0005, -0.0170,  0.0685, -0.0264, -0.0080,\n",
      "         -0.0235, -0.0059,  0.0035, -0.0622],\n",
      "        [-0.1052, -0.0913, -0.0404,  0.0448, -0.0257,  0.0106,  0.1009, -0.0054,\n",
      "         -0.1087, -0.0264, -0.0615,  0.0896, -0.0093, -0.0680, -0.0800,  0.0190,\n",
      "         -0.0313,  0.0057,  0.0787,  0.0372, -0.0778,  0.0085,  0.0255,  0.0834,\n",
      "         -0.1014, -0.0715, -0.0227, -0.0298, -0.0805,  0.0416, -0.0897,  0.0338,\n",
      "          0.0356, -0.0254,  0.0878, -0.0341,  0.0007, -0.1015,  0.0599,  0.0345,\n",
      "         -0.0152,  0.0358, -0.0209,  0.0937,  0.0352,  0.0778, -0.0962,  0.0840,\n",
      "         -0.0874,  0.0159, -0.0146, -0.0819,  0.0439,  0.0028,  0.0098,  0.0538,\n",
      "         -0.0662,  0.0355,  0.0549, -0.0746,  0.0963,  0.0804,  0.0311, -0.0127,\n",
      "          0.0405, -0.0202,  0.0672,  0.0025, -0.0999,  0.0858, -0.0743,  0.0378,\n",
      "         -0.0126, -0.0578,  0.0628,  0.0118,  0.0585,  0.0464, -0.0555,  0.0733,\n",
      "         -0.0949, -0.0050,  0.0268, -0.0054],\n",
      "        [-0.0906, -0.0848, -0.0170,  0.0283,  0.0544,  0.0664, -0.0073, -0.0467,\n",
      "         -0.0181, -0.0429, -0.0255,  0.1072,  0.0145, -0.0606,  0.0014,  0.0714,\n",
      "         -0.0343,  0.0614,  0.0081, -0.0428,  0.0332,  0.0397,  0.0154, -0.0498,\n",
      "          0.0861, -0.0914, -0.0816, -0.0777, -0.0866, -0.0940,  0.0176,  0.0831,\n",
      "          0.0354, -0.0472,  0.0437, -0.0736,  0.0022, -0.0138,  0.0422,  0.0483,\n",
      "         -0.0144, -0.0496,  0.0443,  0.0368, -0.0528, -0.0829,  0.0711,  0.0934,\n",
      "         -0.0029,  0.0684, -0.0261,  0.0551,  0.0682,  0.0914,  0.1038,  0.0803,\n",
      "         -0.0790, -0.0209,  0.0375, -0.0524, -0.0570,  0.0701,  0.0313,  0.0839,\n",
      "         -0.0201, -0.0475, -0.0309,  0.0649, -0.0697,  0.0249,  0.0896, -0.0525,\n",
      "          0.0145, -0.0776, -0.0002,  0.0394,  0.0957, -0.0170,  0.0210,  0.0136,\n",
      "          0.0519,  0.0073,  0.1064, -0.0431],\n",
      "        [-0.0635,  0.0193, -0.0022,  0.0775,  0.0420, -0.1070, -0.0506, -0.0051,\n",
      "          0.0132, -0.0768, -0.0615,  0.0313, -0.0921, -0.1085,  0.0412,  0.0543,\n",
      "          0.0745, -0.0145,  0.0773, -0.0201, -0.0196, -0.0135,  0.0791,  0.0531,\n",
      "          0.0962, -0.1040,  0.0853,  0.0114, -0.0566,  0.0211,  0.0478, -0.0495,\n",
      "          0.0539, -0.1024, -0.0651,  0.0448, -0.0517, -0.0833,  0.0589,  0.0279,\n",
      "          0.0400, -0.1037, -0.0204,  0.0929,  0.0209, -0.0784,  0.0657, -0.0733,\n",
      "         -0.0883,  0.1089, -0.0306,  0.0461, -0.0586, -0.0991, -0.0254, -0.0653,\n",
      "          0.0348,  0.0417, -0.0775,  0.0782, -0.0933, -0.0020, -0.0680, -0.0690,\n",
      "         -0.0736,  0.0634,  0.0241,  0.0598,  0.0370, -0.0296, -0.0626,  0.1030,\n",
      "         -0.0950,  0.0501, -0.1023,  0.0392, -0.0295,  0.0965, -0.0459, -0.0805,\n",
      "          0.0881,  0.0415, -0.0685,  0.1079],\n",
      "        [ 0.0729,  0.0654,  0.0972, -0.1065,  0.0496, -0.0834,  0.0536,  0.0621,\n",
      "         -0.1057, -0.0891, -0.0271, -0.0774, -0.0351,  0.0307, -0.0991, -0.0139,\n",
      "         -0.0213,  0.0709, -0.0357, -0.0653,  0.0065, -0.0223,  0.0613,  0.0255,\n",
      "          0.0793,  0.0612,  0.0837,  0.0102, -0.0889, -0.0774,  0.0643,  0.0494,\n",
      "          0.0541,  0.0267,  0.0494, -0.0554,  0.0178, -0.0604,  0.0124,  0.0947,\n",
      "          0.0954,  0.0004, -0.0636,  0.0028, -0.0011, -0.0486,  0.0172, -0.0987,\n",
      "          0.0957,  0.1034, -0.0383,  0.0327,  0.0892,  0.0230,  0.0259,  0.1036,\n",
      "          0.0075,  0.0181, -0.0885,  0.0246,  0.0860, -0.0722,  0.0398,  0.0169,\n",
      "          0.0167,  0.0270,  0.0938, -0.0245,  0.0712,  0.0013,  0.0350,  0.0207,\n",
      "         -0.0170, -0.0587, -0.0430, -0.0098, -0.1072,  0.0180,  0.1040, -0.1009,\n",
      "         -0.0072, -0.0515,  0.0512, -0.0719]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0429,  0.0394, -0.0856, -0.0250, -0.0125,  0.0262,  0.0491,  0.0896,\n",
      "         0.0299, -0.0513], requires_grad=True)]\n",
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# 定义了一个前馈函数，反向传播函数被自动通过 autograd 定义。可以使用任何张量操作在前馈函数上\n",
    "params = list(net.parameters())\n",
    "print(params)\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.处理输入，调用反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400])\n",
      "tensor([[[[ 0.1410,  0.0656,  0.8847,  ...,  1.0742, -2.1916,  0.0191],\n",
      "          [ 0.2862, -1.4059,  2.5971,  ...,  0.0371,  1.0758, -0.3404],\n",
      "          [ 1.3754,  1.0421,  0.5606,  ...,  0.3113,  0.6303,  0.0870],\n",
      "          ...,\n",
      "          [ 1.1281,  0.0157, -0.5550,  ...,  0.4896, -0.3716,  2.1073],\n",
      "          [ 0.6121,  2.4070, -0.1312,  ..., -0.2073, -1.5819,  1.3727],\n",
      "          [-1.1189,  2.3323, -1.2708,  ..., -1.1971,  0.3736, -1.8210]]]])\n",
      "tensor([[ 0.0246,  0.0646, -0.1019, -0.0359,  0.0387,  0.0608,  0.0526,  0.1081,\n",
      "         -0.0086, -0.0436]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 随机生成一个32x32的输入\n",
    "input = torch.randn(1,1,32,32)\n",
    "out = net(input)\n",
    "print(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2264, -0.4808, -0.4831, -1.4269, -0.3363, -0.7751, -1.4564,  1.0399,\n",
      "          0.2601,  1.3453]])\n"
     ]
    }
   ],
   "source": [
    "# 所有参数梯度缓存器置零，用随机的梯度来反向传播\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))\n",
    "print(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.计算loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400])\n",
      "tensor([-0.6647,  0.4939, -0.1575,  0.2591,  1.1398,  0.5038, -0.5245, -0.9105,\n",
      "        -0.5328, -0.2107])\n",
      "tensor([[-0.6647,  0.4939, -0.1575,  0.2591,  1.1398,  0.5038, -0.5245, -0.9105,\n",
      "         -0.5328, -0.2107]])\n",
      "tensor(0.3831, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 简单的损失函数，MSEloss：均方差\n",
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "print(target)\n",
    "target = target.view(1, -1)\n",
    "print(target)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000015944F944C8>\n",
      "<AddmmBackward object at 0x0000015944F94088>\n",
      "<AccumulateGrad object at 0x0000015944F944C8>\n"
     ]
    }
   ],
   "source": [
    "# 当调用loss.backward()，整个图都会微分.\n",
    "# 所有在图中requires_grad=True 的张量将会让他们的grad张量累计梯度\n",
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear \n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0025,  0.0041, -0.0003, -0.0119, -0.0018,  0.0049])\n"
     ]
    }
   ],
   "source": [
    "'''反向传播'''\n",
    "#  con1 的偏置项在反向传播之前和之后的变化\n",
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.更新神经网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机梯度下降\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "# 其他更新规则\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "optimizer.zero_grad()  # 清零\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()  # does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
