{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考：Pytorch 之 MNIST 数据集实现\n",
    "  \n",
    " 链接🔗：https://blog.csdn.net/weixin_37589575/article/details/95856667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean = [0.5, 0.5 ,0.5], std = [0.5, 0.5, 0.5])])\n",
    "# 图片变换:\n",
    "# ToTensor()把灰度范围从0-255变换到0-1之间\n",
    "# transform.Normalize()把0-1变换到(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = datasets.MNIST(root = \"./data/\",\n",
    "                            transform = transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = datasets.MNIST(root=\"./data/\",\n",
    "                           transform = transform,\n",
    "                           train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndataset: 将要加载的数据的数据集\\nbatch_size(int): 每迭代加载的图像的数量\\nshuffle(bool):将其设置为True时，数据将会在每个epoch之后，进行打乱重新排序\\nnum_workers(int):定义加在数据的线程数，默认为0，意味着只使用主线程加载数据。\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(dataset = data_train,\n",
    "                                               batch_size = 64,\n",
    "                                               shuffle = True,\n",
    "                                               num_workers = 2)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset = data_test,\n",
    "                                              batch_size = 64,\n",
    "                                              shuffle = True,\n",
    "                                              num_workers = 2)\n",
    "'''\n",
    "dataset: 将要加载的数据的数据集\n",
    "batch_size(int): 每迭代加载的图像的数量\n",
    "shuffle(bool):将其设置为True时，数据将会在每个epoch之后，进行打乱重新排序\n",
    "num_workers(int):定义加在数据的线程数，默认为0，意味着只使用主线程加载数据。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 28, 28] doesn't match the broadcast shape [3, 28, 28]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-628b5de10e39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\envs\\Bling\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\Bling\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\Bling\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \"\"\"\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\Bling\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [1, 28, 28] doesn't match the broadcast shape [3, 28, 28]"
     ]
    }
   ],
   "source": [
    "print(data_train[0])  # 会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-3f560bd4bb66>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-3f560bd4bb66>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    img = img.numpy().transpose(1,2,0)\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(data_loader_train))\n",
    "print(imagesimg = torchvision.utils.make_grid(images)\n",
    "\n",
    "img = img.numpy().transpose(1,2,0)\n",
    "std = [0.5,0.5,0.5]\n",
    "mean = [0.5,0.5,0.5]\n",
    "img = img*std+mean\n",
    "print([labels[i] for i in range(64)])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重新开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'batch_size': batch_size}\n",
    "\n",
    "if use_cuda:\n",
    "    kwargs.update({'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True},\n",
    "                   )\n",
    "\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.008\n",
    "epochs = 20\n",
    "gamma = 0.1\n",
    "log_interval = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "dataset2 = datasets.MNIST('./data', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset1,**kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma = gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.335568\n",
      "Train Epoch: 1 [2048/60000 (3%)]\tLoss: 2.152317\n",
      "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 1.990494\n",
      "Train Epoch: 1 [6144/60000 (10%)]\tLoss: 1.736615\n",
      "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 1.368946\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.263340\n",
      "Train Epoch: 1 [12288/60000 (20%)]\tLoss: 0.962070\n",
      "Train Epoch: 1 [14336/60000 (24%)]\tLoss: 0.882994\n",
      "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 1.013182\n",
      "Train Epoch: 1 [18432/60000 (31%)]\tLoss: 0.959295\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.849990\n",
      "Train Epoch: 1 [22528/60000 (38%)]\tLoss: 0.623258\n",
      "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 0.977802\n",
      "Train Epoch: 1 [26624/60000 (44%)]\tLoss: 0.674462\n",
      "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 0.822928\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.413114\n",
      "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 0.841556\n",
      "Train Epoch: 1 [34816/60000 (58%)]\tLoss: 0.630331\n",
      "Train Epoch: 1 [36864/60000 (61%)]\tLoss: 0.478038\n",
      "Train Epoch: 1 [38912/60000 (65%)]\tLoss: 0.473770\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.448049\n",
      "Train Epoch: 1 [43008/60000 (72%)]\tLoss: 0.376939\n",
      "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 0.382732\n",
      "Train Epoch: 1 [47104/60000 (78%)]\tLoss: 0.325564\n",
      "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 0.609387\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.597324\n",
      "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 0.310671\n",
      "Train Epoch: 1 [55296/60000 (92%)]\tLoss: 0.572357\n",
      "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 0.390834\n",
      "Train Epoch: 1 [59392/60000 (99%)]\tLoss: 0.333973\n",
      "\n",
      "Test set: Average loss: 0.3164, Accuracy: 9103/10000 (91%)\n",
      "\n",
      "2\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.308522\n",
      "Train Epoch: 2 [2048/60000 (3%)]\tLoss: 0.327757\n",
      "Train Epoch: 2 [4096/60000 (7%)]\tLoss: 0.363862\n",
      "Train Epoch: 2 [6144/60000 (10%)]\tLoss: 0.514049\n",
      "Train Epoch: 2 [8192/60000 (14%)]\tLoss: 0.447668\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.462371\n",
      "Train Epoch: 2 [12288/60000 (20%)]\tLoss: 0.448286\n",
      "Train Epoch: 2 [14336/60000 (24%)]\tLoss: 0.441904\n",
      "Train Epoch: 2 [16384/60000 (27%)]\tLoss: 0.349529\n",
      "Train Epoch: 2 [18432/60000 (31%)]\tLoss: 0.337959\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.750756\n",
      "Train Epoch: 2 [22528/60000 (38%)]\tLoss: 0.237189\n",
      "Train Epoch: 2 [24576/60000 (41%)]\tLoss: 0.440009\n",
      "Train Epoch: 2 [26624/60000 (44%)]\tLoss: 0.297198\n",
      "Train Epoch: 2 [28672/60000 (48%)]\tLoss: 0.562855\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.638900\n",
      "Train Epoch: 2 [32768/60000 (55%)]\tLoss: 0.440049\n",
      "Train Epoch: 2 [34816/60000 (58%)]\tLoss: 0.593135\n",
      "Train Epoch: 2 [36864/60000 (61%)]\tLoss: 0.342562\n",
      "Train Epoch: 2 [38912/60000 (65%)]\tLoss: 0.587389\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.573252\n",
      "Train Epoch: 2 [43008/60000 (72%)]\tLoss: 0.607030\n",
      "Train Epoch: 2 [45056/60000 (75%)]\tLoss: 0.680471\n",
      "Train Epoch: 2 [47104/60000 (78%)]\tLoss: 0.250644\n",
      "Train Epoch: 2 [49152/60000 (82%)]\tLoss: 0.455104\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.473444\n",
      "Train Epoch: 2 [53248/60000 (89%)]\tLoss: 0.401462\n",
      "Train Epoch: 2 [55296/60000 (92%)]\tLoss: 0.336243\n",
      "Train Epoch: 2 [57344/60000 (96%)]\tLoss: 0.463364\n",
      "Train Epoch: 2 [59392/60000 (99%)]\tLoss: 0.446577\n",
      "\n",
      "Test set: Average loss: 0.2943, Accuracy: 9183/10000 (92%)\n",
      "\n",
      "3\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.348433\n",
      "Train Epoch: 3 [2048/60000 (3%)]\tLoss: 0.386089\n",
      "Train Epoch: 3 [4096/60000 (7%)]\tLoss: 0.417690\n",
      "Train Epoch: 3 [6144/60000 (10%)]\tLoss: 0.301149\n",
      "Train Epoch: 3 [8192/60000 (14%)]\tLoss: 0.515283\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.613786\n",
      "Train Epoch: 3 [12288/60000 (20%)]\tLoss: 0.532558\n",
      "Train Epoch: 3 [14336/60000 (24%)]\tLoss: 0.480456\n",
      "Train Epoch: 3 [16384/60000 (27%)]\tLoss: 0.618763\n",
      "Train Epoch: 3 [18432/60000 (31%)]\tLoss: 0.386802\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.454834\n",
      "Train Epoch: 3 [22528/60000 (38%)]\tLoss: 0.270064\n",
      "Train Epoch: 3 [24576/60000 (41%)]\tLoss: 0.650660\n",
      "Train Epoch: 3 [26624/60000 (44%)]\tLoss: 0.434331\n",
      "Train Epoch: 3 [28672/60000 (48%)]\tLoss: 0.486272\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.445290\n",
      "Train Epoch: 3 [32768/60000 (55%)]\tLoss: 0.958524\n",
      "Train Epoch: 3 [34816/60000 (58%)]\tLoss: 0.507421\n",
      "Train Epoch: 3 [36864/60000 (61%)]\tLoss: 0.804886\n",
      "Train Epoch: 3 [38912/60000 (65%)]\tLoss: 0.432840\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.372601\n",
      "Train Epoch: 3 [43008/60000 (72%)]\tLoss: 0.452845\n",
      "Train Epoch: 3 [45056/60000 (75%)]\tLoss: 0.366829\n",
      "Train Epoch: 3 [47104/60000 (78%)]\tLoss: 0.451751\n",
      "Train Epoch: 3 [49152/60000 (82%)]\tLoss: 0.243684\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.401785\n",
      "Train Epoch: 3 [53248/60000 (89%)]\tLoss: 0.536874\n",
      "Train Epoch: 3 [55296/60000 (92%)]\tLoss: 0.407520\n",
      "Train Epoch: 3 [57344/60000 (96%)]\tLoss: 0.505609\n",
      "Train Epoch: 3 [59392/60000 (99%)]\tLoss: 0.286756\n",
      "\n",
      "Test set: Average loss: 0.2927, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "4\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.440737\n",
      "Train Epoch: 4 [2048/60000 (3%)]\tLoss: 0.338117\n",
      "Train Epoch: 4 [4096/60000 (7%)]\tLoss: 0.269436\n",
      "Train Epoch: 4 [6144/60000 (10%)]\tLoss: 0.586431\n",
      "Train Epoch: 4 [8192/60000 (14%)]\tLoss: 0.315094\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.577799\n",
      "Train Epoch: 4 [12288/60000 (20%)]\tLoss: 0.422174\n",
      "Train Epoch: 4 [14336/60000 (24%)]\tLoss: 0.542317\n",
      "Train Epoch: 4 [16384/60000 (27%)]\tLoss: 0.629583\n",
      "Train Epoch: 4 [18432/60000 (31%)]\tLoss: 0.305726\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.586757\n",
      "Train Epoch: 4 [22528/60000 (38%)]\tLoss: 0.431039\n",
      "Train Epoch: 4 [24576/60000 (41%)]\tLoss: 0.519151\n",
      "Train Epoch: 4 [26624/60000 (44%)]\tLoss: 0.322512\n",
      "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.327053\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.332320\n",
      "Train Epoch: 4 [32768/60000 (55%)]\tLoss: 0.419932\n",
      "Train Epoch: 4 [34816/60000 (58%)]\tLoss: 0.324006\n",
      "Train Epoch: 4 [36864/60000 (61%)]\tLoss: 0.355601\n",
      "Train Epoch: 4 [38912/60000 (65%)]\tLoss: 0.421603\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.377775\n",
      "Train Epoch: 4 [43008/60000 (72%)]\tLoss: 0.558331\n",
      "Train Epoch: 4 [45056/60000 (75%)]\tLoss: 0.466909\n",
      "Train Epoch: 4 [47104/60000 (78%)]\tLoss: 0.651807\n",
      "Train Epoch: 4 [49152/60000 (82%)]\tLoss: 0.460514\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.310344\n",
      "Train Epoch: 4 [53248/60000 (89%)]\tLoss: 0.374992\n",
      "Train Epoch: 4 [55296/60000 (92%)]\tLoss: 0.480840\n",
      "Train Epoch: 4 [57344/60000 (96%)]\tLoss: 0.406494\n",
      "Train Epoch: 4 [59392/60000 (99%)]\tLoss: 0.411451\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "5\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.600030\n",
      "Train Epoch: 5 [2048/60000 (3%)]\tLoss: 0.581251\n",
      "Train Epoch: 5 [4096/60000 (7%)]\tLoss: 0.537126\n",
      "Train Epoch: 5 [6144/60000 (10%)]\tLoss: 0.612302\n",
      "Train Epoch: 5 [8192/60000 (14%)]\tLoss: 0.399130\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.544794\n",
      "Train Epoch: 5 [12288/60000 (20%)]\tLoss: 0.430446\n",
      "Train Epoch: 5 [14336/60000 (24%)]\tLoss: 0.312988\n",
      "Train Epoch: 5 [16384/60000 (27%)]\tLoss: 0.278284\n",
      "Train Epoch: 5 [18432/60000 (31%)]\tLoss: 0.422562\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.273293\n",
      "Train Epoch: 5 [22528/60000 (38%)]\tLoss: 0.414233\n",
      "Train Epoch: 5 [24576/60000 (41%)]\tLoss: 0.261751\n",
      "Train Epoch: 5 [26624/60000 (44%)]\tLoss: 0.322790\n",
      "Train Epoch: 5 [28672/60000 (48%)]\tLoss: 0.271279\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.480169\n",
      "Train Epoch: 5 [32768/60000 (55%)]\tLoss: 0.324440\n",
      "Train Epoch: 5 [34816/60000 (58%)]\tLoss: 0.356249\n",
      "Train Epoch: 5 [36864/60000 (61%)]\tLoss: 0.516680\n",
      "Train Epoch: 5 [38912/60000 (65%)]\tLoss: 0.221859\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.383355\n",
      "Train Epoch: 5 [43008/60000 (72%)]\tLoss: 0.340582\n",
      "Train Epoch: 5 [45056/60000 (75%)]\tLoss: 0.381696\n",
      "Train Epoch: 5 [47104/60000 (78%)]\tLoss: 0.326103\n",
      "Train Epoch: 5 [49152/60000 (82%)]\tLoss: 0.609587\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.442236\n",
      "Train Epoch: 5 [53248/60000 (89%)]\tLoss: 0.310162\n",
      "Train Epoch: 5 [55296/60000 (92%)]\tLoss: 0.609020\n",
      "Train Epoch: 5 [57344/60000 (96%)]\tLoss: 0.419114\n",
      "Train Epoch: 5 [59392/60000 (99%)]\tLoss: 0.529532\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "6\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.545870\n",
      "Train Epoch: 6 [2048/60000 (3%)]\tLoss: 0.373859\n",
      "Train Epoch: 6 [4096/60000 (7%)]\tLoss: 0.606802\n",
      "Train Epoch: 6 [6144/60000 (10%)]\tLoss: 0.381107\n",
      "Train Epoch: 6 [8192/60000 (14%)]\tLoss: 0.579154\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.387613\n",
      "Train Epoch: 6 [12288/60000 (20%)]\tLoss: 0.438646\n",
      "Train Epoch: 6 [14336/60000 (24%)]\tLoss: 0.296108\n",
      "Train Epoch: 6 [16384/60000 (27%)]\tLoss: 0.541851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [18432/60000 (31%)]\tLoss: 0.393795\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.533592\n",
      "Train Epoch: 6 [22528/60000 (38%)]\tLoss: 0.490829\n",
      "Train Epoch: 6 [24576/60000 (41%)]\tLoss: 0.463020\n",
      "Train Epoch: 6 [26624/60000 (44%)]\tLoss: 0.578163\n",
      "Train Epoch: 6 [28672/60000 (48%)]\tLoss: 0.305690\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.683618\n",
      "Train Epoch: 6 [32768/60000 (55%)]\tLoss: 0.344311\n",
      "Train Epoch: 6 [34816/60000 (58%)]\tLoss: 0.237790\n",
      "Train Epoch: 6 [36864/60000 (61%)]\tLoss: 0.327802\n",
      "Train Epoch: 6 [38912/60000 (65%)]\tLoss: 0.437296\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.367026\n",
      "Train Epoch: 6 [43008/60000 (72%)]\tLoss: 0.483164\n",
      "Train Epoch: 6 [45056/60000 (75%)]\tLoss: 0.276051\n",
      "Train Epoch: 6 [47104/60000 (78%)]\tLoss: 0.630269\n",
      "Train Epoch: 6 [49152/60000 (82%)]\tLoss: 0.667350\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.423695\n",
      "Train Epoch: 6 [53248/60000 (89%)]\tLoss: 0.562194\n",
      "Train Epoch: 6 [55296/60000 (92%)]\tLoss: 0.609625\n",
      "Train Epoch: 6 [57344/60000 (96%)]\tLoss: 0.569428\n",
      "Train Epoch: 6 [59392/60000 (99%)]\tLoss: 0.408828\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "7\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.373592\n",
      "Train Epoch: 7 [2048/60000 (3%)]\tLoss: 0.657625\n",
      "Train Epoch: 7 [4096/60000 (7%)]\tLoss: 0.297340\n",
      "Train Epoch: 7 [6144/60000 (10%)]\tLoss: 0.577388\n",
      "Train Epoch: 7 [8192/60000 (14%)]\tLoss: 0.452077\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.554394\n",
      "Train Epoch: 7 [12288/60000 (20%)]\tLoss: 0.426562\n",
      "Train Epoch: 7 [14336/60000 (24%)]\tLoss: 0.362431\n",
      "Train Epoch: 7 [16384/60000 (27%)]\tLoss: 0.405654\n",
      "Train Epoch: 7 [18432/60000 (31%)]\tLoss: 0.469439\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.217449\n",
      "Train Epoch: 7 [22528/60000 (38%)]\tLoss: 0.342377\n",
      "Train Epoch: 7 [24576/60000 (41%)]\tLoss: 0.311282\n",
      "Train Epoch: 7 [26624/60000 (44%)]\tLoss: 0.266858\n",
      "Train Epoch: 7 [28672/60000 (48%)]\tLoss: 0.571245\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.351359\n",
      "Train Epoch: 7 [32768/60000 (55%)]\tLoss: 0.551502\n",
      "Train Epoch: 7 [34816/60000 (58%)]\tLoss: 0.457707\n",
      "Train Epoch: 7 [36864/60000 (61%)]\tLoss: 0.277510\n",
      "Train Epoch: 7 [38912/60000 (65%)]\tLoss: 0.534272\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.593821\n",
      "Train Epoch: 7 [43008/60000 (72%)]\tLoss: 0.437407\n",
      "Train Epoch: 7 [45056/60000 (75%)]\tLoss: 0.428147\n",
      "Train Epoch: 7 [47104/60000 (78%)]\tLoss: 0.256284\n",
      "Train Epoch: 7 [49152/60000 (82%)]\tLoss: 0.473219\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.588746\n",
      "Train Epoch: 7 [53248/60000 (89%)]\tLoss: 0.523622\n",
      "Train Epoch: 7 [55296/60000 (92%)]\tLoss: 0.365164\n",
      "Train Epoch: 7 [57344/60000 (96%)]\tLoss: 0.441953\n",
      "Train Epoch: 7 [59392/60000 (99%)]\tLoss: 0.485127\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "8\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.576937\n",
      "Train Epoch: 8 [2048/60000 (3%)]\tLoss: 0.258067\n",
      "Train Epoch: 8 [4096/60000 (7%)]\tLoss: 0.757620\n",
      "Train Epoch: 8 [6144/60000 (10%)]\tLoss: 0.632560\n",
      "Train Epoch: 8 [8192/60000 (14%)]\tLoss: 0.387171\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.731538\n",
      "Train Epoch: 8 [12288/60000 (20%)]\tLoss: 0.489898\n",
      "Train Epoch: 8 [14336/60000 (24%)]\tLoss: 0.573998\n",
      "Train Epoch: 8 [16384/60000 (27%)]\tLoss: 0.463241\n",
      "Train Epoch: 8 [18432/60000 (31%)]\tLoss: 0.227791\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.237563\n",
      "Train Epoch: 8 [22528/60000 (38%)]\tLoss: 0.319450\n",
      "Train Epoch: 8 [24576/60000 (41%)]\tLoss: 0.564966\n",
      "Train Epoch: 8 [26624/60000 (44%)]\tLoss: 0.295027\n",
      "Train Epoch: 8 [28672/60000 (48%)]\tLoss: 0.328926\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.608022\n",
      "Train Epoch: 8 [32768/60000 (55%)]\tLoss: 0.561447\n",
      "Train Epoch: 8 [34816/60000 (58%)]\tLoss: 0.328382\n",
      "Train Epoch: 8 [36864/60000 (61%)]\tLoss: 0.491561\n",
      "Train Epoch: 8 [38912/60000 (65%)]\tLoss: 0.304528\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.338408\n",
      "Train Epoch: 8 [43008/60000 (72%)]\tLoss: 0.473420\n",
      "Train Epoch: 8 [45056/60000 (75%)]\tLoss: 0.694054\n",
      "Train Epoch: 8 [47104/60000 (78%)]\tLoss: 0.270121\n",
      "Train Epoch: 8 [49152/60000 (82%)]\tLoss: 0.318678\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.284870\n",
      "Train Epoch: 8 [53248/60000 (89%)]\tLoss: 0.438111\n",
      "Train Epoch: 8 [55296/60000 (92%)]\tLoss: 0.376566\n",
      "Train Epoch: 8 [57344/60000 (96%)]\tLoss: 0.519563\n",
      "Train Epoch: 8 [59392/60000 (99%)]\tLoss: 0.477719\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "9\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.602205\n",
      "Train Epoch: 9 [2048/60000 (3%)]\tLoss: 0.407846\n",
      "Train Epoch: 9 [4096/60000 (7%)]\tLoss: 0.449949\n",
      "Train Epoch: 9 [6144/60000 (10%)]\tLoss: 0.470593\n",
      "Train Epoch: 9 [8192/60000 (14%)]\tLoss: 0.444377\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.434699\n",
      "Train Epoch: 9 [12288/60000 (20%)]\tLoss: 0.378965\n",
      "Train Epoch: 9 [14336/60000 (24%)]\tLoss: 0.421155\n",
      "Train Epoch: 9 [16384/60000 (27%)]\tLoss: 0.440382\n",
      "Train Epoch: 9 [18432/60000 (31%)]\tLoss: 0.569090\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.413487\n",
      "Train Epoch: 9 [22528/60000 (38%)]\tLoss: 0.357686\n",
      "Train Epoch: 9 [24576/60000 (41%)]\tLoss: 0.379595\n",
      "Train Epoch: 9 [26624/60000 (44%)]\tLoss: 0.380894\n",
      "Train Epoch: 9 [28672/60000 (48%)]\tLoss: 0.336555\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.520627\n",
      "Train Epoch: 9 [32768/60000 (55%)]\tLoss: 0.578448\n",
      "Train Epoch: 9 [34816/60000 (58%)]\tLoss: 0.569479\n",
      "Train Epoch: 9 [36864/60000 (61%)]\tLoss: 0.369096\n",
      "Train Epoch: 9 [38912/60000 (65%)]\tLoss: 0.309895\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.215189\n",
      "Train Epoch: 9 [43008/60000 (72%)]\tLoss: 0.404756\n",
      "Train Epoch: 9 [45056/60000 (75%)]\tLoss: 0.387057\n",
      "Train Epoch: 9 [47104/60000 (78%)]\tLoss: 0.223303\n",
      "Train Epoch: 9 [49152/60000 (82%)]\tLoss: 0.370279\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.409678\n",
      "Train Epoch: 9 [53248/60000 (89%)]\tLoss: 0.385076\n",
      "Train Epoch: 9 [55296/60000 (92%)]\tLoss: 0.466610\n",
      "Train Epoch: 9 [57344/60000 (96%)]\tLoss: 0.432498\n",
      "Train Epoch: 9 [59392/60000 (99%)]\tLoss: 0.732473\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "10\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.522093\n",
      "Train Epoch: 10 [2048/60000 (3%)]\tLoss: 0.325973\n",
      "Train Epoch: 10 [4096/60000 (7%)]\tLoss: 0.658852\n",
      "Train Epoch: 10 [6144/60000 (10%)]\tLoss: 0.433847\n",
      "Train Epoch: 10 [8192/60000 (14%)]\tLoss: 0.627268\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.298048\n",
      "Train Epoch: 10 [12288/60000 (20%)]\tLoss: 0.454031\n",
      "Train Epoch: 10 [14336/60000 (24%)]\tLoss: 0.436870\n",
      "Train Epoch: 10 [16384/60000 (27%)]\tLoss: 0.314945\n",
      "Train Epoch: 10 [18432/60000 (31%)]\tLoss: 0.345109\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.348808\n",
      "Train Epoch: 10 [22528/60000 (38%)]\tLoss: 0.633206\n",
      "Train Epoch: 10 [24576/60000 (41%)]\tLoss: 0.329368\n",
      "Train Epoch: 10 [26624/60000 (44%)]\tLoss: 0.299393\n",
      "Train Epoch: 10 [28672/60000 (48%)]\tLoss: 0.386100\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.388872\n",
      "Train Epoch: 10 [32768/60000 (55%)]\tLoss: 0.505869\n",
      "Train Epoch: 10 [34816/60000 (58%)]\tLoss: 0.546060\n",
      "Train Epoch: 10 [36864/60000 (61%)]\tLoss: 0.515604\n",
      "Train Epoch: 10 [38912/60000 (65%)]\tLoss: 0.494155\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.493933\n",
      "Train Epoch: 10 [43008/60000 (72%)]\tLoss: 0.636803\n",
      "Train Epoch: 10 [45056/60000 (75%)]\tLoss: 0.251263\n",
      "Train Epoch: 10 [47104/60000 (78%)]\tLoss: 0.296554\n",
      "Train Epoch: 10 [49152/60000 (82%)]\tLoss: 0.548388\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.328173\n",
      "Train Epoch: 10 [53248/60000 (89%)]\tLoss: 0.427723\n",
      "Train Epoch: 10 [55296/60000 (92%)]\tLoss: 0.555265\n",
      "Train Epoch: 10 [57344/60000 (96%)]\tLoss: 0.490309\n",
      "Train Epoch: 10 [59392/60000 (99%)]\tLoss: 0.310074\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "11\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.371513\n",
      "Train Epoch: 11 [2048/60000 (3%)]\tLoss: 0.337505\n",
      "Train Epoch: 11 [4096/60000 (7%)]\tLoss: 0.298794\n",
      "Train Epoch: 11 [6144/60000 (10%)]\tLoss: 0.621883\n",
      "Train Epoch: 11 [8192/60000 (14%)]\tLoss: 0.451440\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.299731\n",
      "Train Epoch: 11 [12288/60000 (20%)]\tLoss: 0.245312\n",
      "Train Epoch: 11 [14336/60000 (24%)]\tLoss: 0.386541\n",
      "Train Epoch: 11 [16384/60000 (27%)]\tLoss: 0.425793\n",
      "Train Epoch: 11 [18432/60000 (31%)]\tLoss: 0.357594\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.365705\n",
      "Train Epoch: 11 [22528/60000 (38%)]\tLoss: 0.562481\n",
      "Train Epoch: 11 [24576/60000 (41%)]\tLoss: 0.477267\n",
      "Train Epoch: 11 [26624/60000 (44%)]\tLoss: 0.346790\n",
      "Train Epoch: 11 [28672/60000 (48%)]\tLoss: 0.317933\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.393703\n",
      "Train Epoch: 11 [32768/60000 (55%)]\tLoss: 0.429785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [34816/60000 (58%)]\tLoss: 0.404816\n",
      "Train Epoch: 11 [36864/60000 (61%)]\tLoss: 0.544327\n",
      "Train Epoch: 11 [38912/60000 (65%)]\tLoss: 0.323941\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.337964\n",
      "Train Epoch: 11 [43008/60000 (72%)]\tLoss: 0.472959\n",
      "Train Epoch: 11 [45056/60000 (75%)]\tLoss: 0.518573\n",
      "Train Epoch: 11 [47104/60000 (78%)]\tLoss: 0.604463\n",
      "Train Epoch: 11 [49152/60000 (82%)]\tLoss: 0.392914\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.441741\n",
      "Train Epoch: 11 [53248/60000 (89%)]\tLoss: 0.274751\n",
      "Train Epoch: 11 [55296/60000 (92%)]\tLoss: 0.398269\n",
      "Train Epoch: 11 [57344/60000 (96%)]\tLoss: 0.599217\n",
      "Train Epoch: 11 [59392/60000 (99%)]\tLoss: 0.431373\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "12\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.212117\n",
      "Train Epoch: 12 [2048/60000 (3%)]\tLoss: 0.476271\n",
      "Train Epoch: 12 [4096/60000 (7%)]\tLoss: 0.317407\n",
      "Train Epoch: 12 [6144/60000 (10%)]\tLoss: 0.376307\n",
      "Train Epoch: 12 [8192/60000 (14%)]\tLoss: 0.496690\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.524938\n",
      "Train Epoch: 12 [12288/60000 (20%)]\tLoss: 0.451944\n",
      "Train Epoch: 12 [14336/60000 (24%)]\tLoss: 0.218724\n",
      "Train Epoch: 12 [16384/60000 (27%)]\tLoss: 0.200273\n",
      "Train Epoch: 12 [18432/60000 (31%)]\tLoss: 0.249773\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.432804\n",
      "Train Epoch: 12 [22528/60000 (38%)]\tLoss: 0.422697\n",
      "Train Epoch: 12 [24576/60000 (41%)]\tLoss: 0.453183\n",
      "Train Epoch: 12 [26624/60000 (44%)]\tLoss: 0.401781\n",
      "Train Epoch: 12 [28672/60000 (48%)]\tLoss: 0.333044\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.319601\n",
      "Train Epoch: 12 [32768/60000 (55%)]\tLoss: 0.399862\n",
      "Train Epoch: 12 [34816/60000 (58%)]\tLoss: 0.420582\n",
      "Train Epoch: 12 [36864/60000 (61%)]\tLoss: 0.417320\n",
      "Train Epoch: 12 [38912/60000 (65%)]\tLoss: 0.477825\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.233175\n",
      "Train Epoch: 12 [43008/60000 (72%)]\tLoss: 0.417798\n",
      "Train Epoch: 12 [45056/60000 (75%)]\tLoss: 0.382847\n",
      "Train Epoch: 12 [47104/60000 (78%)]\tLoss: 0.355857\n",
      "Train Epoch: 12 [49152/60000 (82%)]\tLoss: 0.436686\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.551294\n",
      "Train Epoch: 12 [53248/60000 (89%)]\tLoss: 0.462595\n",
      "Train Epoch: 12 [55296/60000 (92%)]\tLoss: 0.613799\n",
      "Train Epoch: 12 [57344/60000 (96%)]\tLoss: 0.338249\n",
      "Train Epoch: 12 [59392/60000 (99%)]\tLoss: 0.435784\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "13\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.380322\n",
      "Train Epoch: 13 [2048/60000 (3%)]\tLoss: 0.348043\n",
      "Train Epoch: 13 [4096/60000 (7%)]\tLoss: 0.464649\n",
      "Train Epoch: 13 [6144/60000 (10%)]\tLoss: 0.331483\n",
      "Train Epoch: 13 [8192/60000 (14%)]\tLoss: 0.570129\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.295568\n",
      "Train Epoch: 13 [12288/60000 (20%)]\tLoss: 0.373455\n",
      "Train Epoch: 13 [14336/60000 (24%)]\tLoss: 0.393358\n",
      "Train Epoch: 13 [16384/60000 (27%)]\tLoss: 0.626558\n",
      "Train Epoch: 13 [18432/60000 (31%)]\tLoss: 0.637777\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.427173\n",
      "Train Epoch: 13 [22528/60000 (38%)]\tLoss: 0.582045\n",
      "Train Epoch: 13 [24576/60000 (41%)]\tLoss: 0.465787\n",
      "Train Epoch: 13 [26624/60000 (44%)]\tLoss: 0.333773\n",
      "Train Epoch: 13 [28672/60000 (48%)]\tLoss: 0.307656\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.354392\n",
      "Train Epoch: 13 [32768/60000 (55%)]\tLoss: 0.524053\n",
      "Train Epoch: 13 [34816/60000 (58%)]\tLoss: 0.460874\n",
      "Train Epoch: 13 [36864/60000 (61%)]\tLoss: 0.333015\n",
      "Train Epoch: 13 [38912/60000 (65%)]\tLoss: 0.277098\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.356126\n",
      "Train Epoch: 13 [43008/60000 (72%)]\tLoss: 0.387558\n",
      "Train Epoch: 13 [45056/60000 (75%)]\tLoss: 0.553772\n",
      "Train Epoch: 13 [47104/60000 (78%)]\tLoss: 0.540077\n",
      "Train Epoch: 13 [49152/60000 (82%)]\tLoss: 0.405759\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.385508\n",
      "Train Epoch: 13 [53248/60000 (89%)]\tLoss: 0.539164\n",
      "Train Epoch: 13 [55296/60000 (92%)]\tLoss: 0.437831\n",
      "Train Epoch: 13 [57344/60000 (96%)]\tLoss: 0.558191\n",
      "Train Epoch: 13 [59392/60000 (99%)]\tLoss: 0.357584\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "14\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.333408\n",
      "Train Epoch: 14 [2048/60000 (3%)]\tLoss: 0.338098\n",
      "Train Epoch: 14 [4096/60000 (7%)]\tLoss: 0.509024\n",
      "Train Epoch: 14 [6144/60000 (10%)]\tLoss: 0.482599\n",
      "Train Epoch: 14 [8192/60000 (14%)]\tLoss: 0.369847\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.388794\n",
      "Train Epoch: 14 [12288/60000 (20%)]\tLoss: 0.398627\n",
      "Train Epoch: 14 [14336/60000 (24%)]\tLoss: 0.555732\n",
      "Train Epoch: 14 [16384/60000 (27%)]\tLoss: 0.558989\n",
      "Train Epoch: 14 [18432/60000 (31%)]\tLoss: 0.368246\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.458790\n",
      "Train Epoch: 14 [22528/60000 (38%)]\tLoss: 0.340969\n",
      "Train Epoch: 14 [24576/60000 (41%)]\tLoss: 0.381586\n",
      "Train Epoch: 14 [26624/60000 (44%)]\tLoss: 0.527722\n",
      "Train Epoch: 14 [28672/60000 (48%)]\tLoss: 0.382525\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.382864\n",
      "Train Epoch: 14 [32768/60000 (55%)]\tLoss: 0.530937\n",
      "Train Epoch: 14 [34816/60000 (58%)]\tLoss: 0.524436\n",
      "Train Epoch: 14 [36864/60000 (61%)]\tLoss: 0.461483\n",
      "Train Epoch: 14 [38912/60000 (65%)]\tLoss: 0.419179\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.503454\n",
      "Train Epoch: 14 [43008/60000 (72%)]\tLoss: 0.454969\n",
      "Train Epoch: 14 [45056/60000 (75%)]\tLoss: 0.280895\n",
      "Train Epoch: 14 [47104/60000 (78%)]\tLoss: 0.348037\n",
      "Train Epoch: 14 [49152/60000 (82%)]\tLoss: 0.568487\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.343667\n",
      "Train Epoch: 14 [53248/60000 (89%)]\tLoss: 0.477556\n",
      "Train Epoch: 14 [55296/60000 (92%)]\tLoss: 0.287161\n",
      "Train Epoch: 14 [57344/60000 (96%)]\tLoss: 0.354393\n",
      "Train Epoch: 14 [59392/60000 (99%)]\tLoss: 0.379423\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "15\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.461352\n",
      "Train Epoch: 15 [2048/60000 (3%)]\tLoss: 0.462510\n",
      "Train Epoch: 15 [4096/60000 (7%)]\tLoss: 0.520568\n",
      "Train Epoch: 15 [6144/60000 (10%)]\tLoss: 0.393120\n",
      "Train Epoch: 15 [8192/60000 (14%)]\tLoss: 0.325842\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.390684\n",
      "Train Epoch: 15 [12288/60000 (20%)]\tLoss: 0.456065\n",
      "Train Epoch: 15 [14336/60000 (24%)]\tLoss: 0.389212\n",
      "Train Epoch: 15 [16384/60000 (27%)]\tLoss: 0.645579\n",
      "Train Epoch: 15 [18432/60000 (31%)]\tLoss: 0.480965\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.611758\n",
      "Train Epoch: 15 [22528/60000 (38%)]\tLoss: 0.438328\n",
      "Train Epoch: 15 [24576/60000 (41%)]\tLoss: 0.429879\n",
      "Train Epoch: 15 [26624/60000 (44%)]\tLoss: 0.236828\n",
      "Train Epoch: 15 [28672/60000 (48%)]\tLoss: 0.379861\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.425140\n",
      "Train Epoch: 15 [32768/60000 (55%)]\tLoss: 0.431245\n",
      "Train Epoch: 15 [34816/60000 (58%)]\tLoss: 0.420412\n",
      "Train Epoch: 15 [36864/60000 (61%)]\tLoss: 0.347605\n",
      "Train Epoch: 15 [38912/60000 (65%)]\tLoss: 0.475921\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.636878\n",
      "Train Epoch: 15 [43008/60000 (72%)]\tLoss: 0.439168\n",
      "Train Epoch: 15 [45056/60000 (75%)]\tLoss: 0.405179\n",
      "Train Epoch: 15 [47104/60000 (78%)]\tLoss: 0.329140\n",
      "Train Epoch: 15 [49152/60000 (82%)]\tLoss: 0.359207\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.452304\n",
      "Train Epoch: 15 [53248/60000 (89%)]\tLoss: 0.486543\n",
      "Train Epoch: 15 [55296/60000 (92%)]\tLoss: 0.451686\n",
      "Train Epoch: 15 [57344/60000 (96%)]\tLoss: 0.414149\n",
      "Train Epoch: 15 [59392/60000 (99%)]\tLoss: 0.409302\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "16\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.315415\n",
      "Train Epoch: 16 [2048/60000 (3%)]\tLoss: 0.602208\n",
      "Train Epoch: 16 [4096/60000 (7%)]\tLoss: 0.562943\n",
      "Train Epoch: 16 [6144/60000 (10%)]\tLoss: 0.368815\n",
      "Train Epoch: 16 [8192/60000 (14%)]\tLoss: 0.294624\n",
      "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.564499\n",
      "Train Epoch: 16 [12288/60000 (20%)]\tLoss: 0.309904\n",
      "Train Epoch: 16 [14336/60000 (24%)]\tLoss: 0.364482\n",
      "Train Epoch: 16 [16384/60000 (27%)]\tLoss: 0.366254\n",
      "Train Epoch: 16 [18432/60000 (31%)]\tLoss: 0.338088\n",
      "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.282157\n",
      "Train Epoch: 16 [22528/60000 (38%)]\tLoss: 0.448710\n",
      "Train Epoch: 16 [24576/60000 (41%)]\tLoss: 0.345118\n",
      "Train Epoch: 16 [26624/60000 (44%)]\tLoss: 0.376796\n",
      "Train Epoch: 16 [28672/60000 (48%)]\tLoss: 0.363272\n",
      "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.509984\n",
      "Train Epoch: 16 [32768/60000 (55%)]\tLoss: 0.399730\n",
      "Train Epoch: 16 [34816/60000 (58%)]\tLoss: 0.425664\n",
      "Train Epoch: 16 [36864/60000 (61%)]\tLoss: 0.589507\n",
      "Train Epoch: 16 [38912/60000 (65%)]\tLoss: 0.550425\n",
      "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.384089\n",
      "Train Epoch: 16 [43008/60000 (72%)]\tLoss: 0.244543\n",
      "Train Epoch: 16 [45056/60000 (75%)]\tLoss: 0.323204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [47104/60000 (78%)]\tLoss: 0.432622\n",
      "Train Epoch: 16 [49152/60000 (82%)]\tLoss: 0.480397\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.514156\n",
      "Train Epoch: 16 [53248/60000 (89%)]\tLoss: 0.725302\n",
      "Train Epoch: 16 [55296/60000 (92%)]\tLoss: 0.240265\n",
      "Train Epoch: 16 [57344/60000 (96%)]\tLoss: 0.385697\n",
      "Train Epoch: 16 [59392/60000 (99%)]\tLoss: 0.675486\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "17\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.369732\n",
      "Train Epoch: 17 [2048/60000 (3%)]\tLoss: 0.439989\n",
      "Train Epoch: 17 [4096/60000 (7%)]\tLoss: 0.425520\n",
      "Train Epoch: 17 [6144/60000 (10%)]\tLoss: 0.533557\n",
      "Train Epoch: 17 [8192/60000 (14%)]\tLoss: 0.286752\n",
      "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.373064\n",
      "Train Epoch: 17 [12288/60000 (20%)]\tLoss: 0.377319\n",
      "Train Epoch: 17 [14336/60000 (24%)]\tLoss: 0.488367\n",
      "Train Epoch: 17 [16384/60000 (27%)]\tLoss: 0.326482\n",
      "Train Epoch: 17 [18432/60000 (31%)]\tLoss: 0.454120\n",
      "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.195377\n",
      "Train Epoch: 17 [22528/60000 (38%)]\tLoss: 0.596450\n",
      "Train Epoch: 17 [24576/60000 (41%)]\tLoss: 0.554952\n",
      "Train Epoch: 17 [26624/60000 (44%)]\tLoss: 0.347017\n",
      "Train Epoch: 17 [28672/60000 (48%)]\tLoss: 0.410455\n",
      "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.335530\n",
      "Train Epoch: 17 [32768/60000 (55%)]\tLoss: 0.437326\n",
      "Train Epoch: 17 [34816/60000 (58%)]\tLoss: 0.501761\n",
      "Train Epoch: 17 [36864/60000 (61%)]\tLoss: 0.240846\n",
      "Train Epoch: 17 [38912/60000 (65%)]\tLoss: 0.619163\n",
      "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.399630\n",
      "Train Epoch: 17 [43008/60000 (72%)]\tLoss: 0.476391\n",
      "Train Epoch: 17 [45056/60000 (75%)]\tLoss: 0.287084\n",
      "Train Epoch: 17 [47104/60000 (78%)]\tLoss: 0.402846\n",
      "Train Epoch: 17 [49152/60000 (82%)]\tLoss: 0.373946\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.337182\n",
      "Train Epoch: 17 [53248/60000 (89%)]\tLoss: 0.339684\n",
      "Train Epoch: 17 [55296/60000 (92%)]\tLoss: 0.481764\n",
      "Train Epoch: 17 [57344/60000 (96%)]\tLoss: 0.428581\n",
      "Train Epoch: 17 [59392/60000 (99%)]\tLoss: 0.225591\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "18\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.617949\n",
      "Train Epoch: 18 [2048/60000 (3%)]\tLoss: 0.316378\n",
      "Train Epoch: 18 [4096/60000 (7%)]\tLoss: 0.223572\n",
      "Train Epoch: 18 [6144/60000 (10%)]\tLoss: 0.418721\n",
      "Train Epoch: 18 [8192/60000 (14%)]\tLoss: 0.396528\n",
      "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.499054\n",
      "Train Epoch: 18 [12288/60000 (20%)]\tLoss: 0.393106\n",
      "Train Epoch: 18 [14336/60000 (24%)]\tLoss: 0.327673\n",
      "Train Epoch: 18 [16384/60000 (27%)]\tLoss: 0.303647\n",
      "Train Epoch: 18 [18432/60000 (31%)]\tLoss: 0.713201\n",
      "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.550173\n",
      "Train Epoch: 18 [22528/60000 (38%)]\tLoss: 0.488169\n",
      "Train Epoch: 18 [24576/60000 (41%)]\tLoss: 0.519775\n",
      "Train Epoch: 18 [26624/60000 (44%)]\tLoss: 0.389354\n",
      "Train Epoch: 18 [28672/60000 (48%)]\tLoss: 0.487231\n",
      "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.390447\n",
      "Train Epoch: 18 [32768/60000 (55%)]\tLoss: 0.319894\n",
      "Train Epoch: 18 [34816/60000 (58%)]\tLoss: 0.491389\n",
      "Train Epoch: 18 [36864/60000 (61%)]\tLoss: 0.344717\n",
      "Train Epoch: 18 [38912/60000 (65%)]\tLoss: 0.509442\n",
      "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.428957\n",
      "Train Epoch: 18 [43008/60000 (72%)]\tLoss: 0.297227\n",
      "Train Epoch: 18 [45056/60000 (75%)]\tLoss: 0.540794\n",
      "Train Epoch: 18 [47104/60000 (78%)]\tLoss: 0.295135\n",
      "Train Epoch: 18 [49152/60000 (82%)]\tLoss: 0.681523\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.403338\n",
      "Train Epoch: 18 [53248/60000 (89%)]\tLoss: 0.499942\n",
      "Train Epoch: 18 [55296/60000 (92%)]\tLoss: 0.459528\n",
      "Train Epoch: 18 [57344/60000 (96%)]\tLoss: 0.490407\n",
      "Train Epoch: 18 [59392/60000 (99%)]\tLoss: 0.664893\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "19\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.362230\n",
      "Train Epoch: 19 [2048/60000 (3%)]\tLoss: 0.278953\n",
      "Train Epoch: 19 [4096/60000 (7%)]\tLoss: 0.402802\n",
      "Train Epoch: 19 [6144/60000 (10%)]\tLoss: 0.342508\n",
      "Train Epoch: 19 [8192/60000 (14%)]\tLoss: 0.296298\n",
      "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.383928\n",
      "Train Epoch: 19 [12288/60000 (20%)]\tLoss: 0.259873\n",
      "Train Epoch: 19 [14336/60000 (24%)]\tLoss: 0.584485\n",
      "Train Epoch: 19 [16384/60000 (27%)]\tLoss: 0.361043\n",
      "Train Epoch: 19 [18432/60000 (31%)]\tLoss: 0.507090\n",
      "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.459897\n",
      "Train Epoch: 19 [22528/60000 (38%)]\tLoss: 0.366395\n",
      "Train Epoch: 19 [24576/60000 (41%)]\tLoss: 0.336112\n",
      "Train Epoch: 19 [26624/60000 (44%)]\tLoss: 0.458389\n",
      "Train Epoch: 19 [28672/60000 (48%)]\tLoss: 0.391338\n",
      "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.347187\n",
      "Train Epoch: 19 [32768/60000 (55%)]\tLoss: 0.640458\n",
      "Train Epoch: 19 [34816/60000 (58%)]\tLoss: 0.546860\n",
      "Train Epoch: 19 [36864/60000 (61%)]\tLoss: 0.386929\n",
      "Train Epoch: 19 [38912/60000 (65%)]\tLoss: 0.296284\n",
      "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.312193\n",
      "Train Epoch: 19 [43008/60000 (72%)]\tLoss: 0.477041\n",
      "Train Epoch: 19 [45056/60000 (75%)]\tLoss: 0.652804\n",
      "Train Epoch: 19 [47104/60000 (78%)]\tLoss: 0.713030\n",
      "Train Epoch: 19 [49152/60000 (82%)]\tLoss: 0.272670\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.355766\n",
      "Train Epoch: 19 [53248/60000 (89%)]\tLoss: 0.446148\n",
      "Train Epoch: 19 [55296/60000 (92%)]\tLoss: 0.472505\n",
      "Train Epoch: 19 [57344/60000 (96%)]\tLoss: 0.513044\n",
      "Train Epoch: 19 [59392/60000 (99%)]\tLoss: 0.422049\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "20\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.387312\n",
      "Train Epoch: 20 [2048/60000 (3%)]\tLoss: 0.478644\n",
      "Train Epoch: 20 [4096/60000 (7%)]\tLoss: 0.479036\n",
      "Train Epoch: 20 [6144/60000 (10%)]\tLoss: 0.491812\n",
      "Train Epoch: 20 [8192/60000 (14%)]\tLoss: 0.258650\n",
      "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.526074\n",
      "Train Epoch: 20 [12288/60000 (20%)]\tLoss: 0.382998\n",
      "Train Epoch: 20 [14336/60000 (24%)]\tLoss: 0.412712\n",
      "Train Epoch: 20 [16384/60000 (27%)]\tLoss: 0.525863\n",
      "Train Epoch: 20 [18432/60000 (31%)]\tLoss: 0.275743\n",
      "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.398125\n",
      "Train Epoch: 20 [22528/60000 (38%)]\tLoss: 0.501254\n",
      "Train Epoch: 20 [24576/60000 (41%)]\tLoss: 0.580361\n",
      "Train Epoch: 20 [26624/60000 (44%)]\tLoss: 0.357955\n",
      "Train Epoch: 20 [28672/60000 (48%)]\tLoss: 0.404325\n",
      "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.289754\n",
      "Train Epoch: 20 [32768/60000 (55%)]\tLoss: 0.377975\n",
      "Train Epoch: 20 [34816/60000 (58%)]\tLoss: 0.313260\n",
      "Train Epoch: 20 [36864/60000 (61%)]\tLoss: 0.524902\n",
      "Train Epoch: 20 [38912/60000 (65%)]\tLoss: 0.648465\n",
      "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.283117\n",
      "Train Epoch: 20 [43008/60000 (72%)]\tLoss: 0.291542\n",
      "Train Epoch: 20 [45056/60000 (75%)]\tLoss: 0.411414\n",
      "Train Epoch: 20 [47104/60000 (78%)]\tLoss: 0.212572\n",
      "Train Epoch: 20 [49152/60000 (82%)]\tLoss: 0.334897\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.378922\n",
      "Train Epoch: 20 [53248/60000 (89%)]\tLoss: 0.279561\n",
      "Train Epoch: 20 [55296/60000 (92%)]\tLoss: 0.381052\n",
      "Train Epoch: 20 [57344/60000 (96%)]\tLoss: 0.337512\n",
      "Train Epoch: 20 [59392/60000 (99%)]\tLoss: 0.328169\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 9196/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    # train(args, model, device, train_loader, optimizer, epoch)\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 32 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            # if args.dry_run:\n",
    "            #     break\n",
    "    \n",
    "    # test(model, device, test_loader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
