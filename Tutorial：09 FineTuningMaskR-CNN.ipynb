{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微调基于torchvision 0.3的目标检测模型\n",
    "  \n",
    "微调在 Penn-Fudan 数据库中对行人检测和分割的已预先训练的 Mask R-CNN 模型。  \n",
    "Penn-Fudan 包含170个图像和345个行人实例，将用它来说明如何在 torchvision 中使用新功能，以便在自定义数据集上训练实例分割模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 新的自定义数据\n",
    "  \n",
    "数据集应该从标准的类torch.utils.data.Dataset继承而来，并实现_len和_getitem_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.1 为数据集编写类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PennFudanDataset(object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\"))))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        mask = Image.open(mask_path)\n",
    "        mask = np.array(mask)\n",
    "        obj_ids = np.unique(mask)\n",
    "        obj_ids = obj_ids[1:]\n",
    "        \n",
    "        # 将颜色编码的mask分成一组\n",
    "        masks = mask = obj_ids[:, None, None]\n",
    "        \n",
    "        # 获取每个mask的边界框坐标\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            x1 = np.min(pos[1])\n",
    "            x2 = np.max(pos[1])\n",
    "            y1 = np.min(pos[0])\n",
    "            y2 = np.max(pos[0])\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype = torch.float32)\n",
    "        labels = torch.ones((num_objs,), dtype = torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype = torch.uint8)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        # 假设所有实例都不是人群 \n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义模型\n",
    "\n",
    "* 1没用\n",
    "* 2没用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1 微调已经预训练的模型：从一个在COCO上已预先训练过的模型开始，为自己的特定类进行微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to C:\\Users\\朱子仪/.cache\\torch\\checkpoints\\fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4d12bac1214148a7f18b5b7e10001c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=167502836.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = True)\n",
    "\n",
    "# 将分类器替换为具有用户定义的 num_classes的新分类器\n",
    "num_classes = 2\n",
    "\n",
    "# 获取分类器的输入参数的数量 \n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# 用新的头部替换预先训练好的头部 \n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2 修改模型以添加不同的主干"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\朱子仪/.cache\\torch\\checkpoints\\mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e7a7304342462387d6d3ea2faca267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14212972.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "backbone = torchvision.models.mobilenet_v2(pretrained = True).features\n",
    "\n",
    "# FasterRCNN需要知道骨干网中的输出通道数量。\n",
    "# 对于mobilenet_v2，它是1280，所以我们需要在这里添加\n",
    "backbone.out_channels = 1280\n",
    "\n",
    "# RPN在每个空间位置生成5 x 3个锚点\n",
    "# 具有5种不同的大小和3种不同的宽高比。\n",
    "# 每个特征映射可能具有不同的大小和宽高比\n",
    "anchor_generator = AnchorGenerator(sizes = ((32,64,128,256,512),),\n",
    "                                  aspect_ratios = ((0.5, 1.0, 2.0),))\n",
    "\n",
    "# 定义用于执行ROI(region of interest)裁剪的特征映射，以及重新缩放后裁剪的大小。\n",
    "# 如果主干返回Tensor，则featmap_names应为[0]。\n",
    "# 更一般地，主干应该返回OrderedDict[Tensor] \n",
    "# 并且在featmap_names中，可以选择要使用的功能映射。 \n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names = [0],\n",
    "                                               output_size = 7,\n",
    "                                               sampling_ratio = 2)\n",
    "\n",
    "# 组合\n",
    "model = FasterRCNN(backbone,\n",
    "                   num_classes=2,\n",
    "                   rpn_anchor_generator = anchor_generator,\n",
    "                   box_roi_pool = roi_pooler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 PennFudan 数据集的实例分割模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor \n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained = True)\n",
    "    \n",
    "    # 获取分类器的输入参数的数量 \n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # 用新的头部替换预先训练好的头部 \n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    # 获取掩膜分类器的输入特征数\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # 用新的掩膜预测器替换掩膜预测器\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, \n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 整合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 为数据扩充 / 转换编写辅助函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as T\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = [] \n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:  \n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))   \n",
    "    return T.Compose(transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate \n",
    "import utils\n",
    "\n",
    "def main():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    # 数据集只有两个类 - 背景和人\n",
    "    dataset = PennFudanDataset('./data/PennFudanPed', get_transform(train=True))\n",
    "    dataset_test = PennFudanDataset('./data/PennFudanPed', get_transform(train=False))\n",
    "    \n",
    "    # 在训练和测试集中拆分数据集\n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "    dataset_test = torch.utils.data.Subset(dataset, indices[-50:])\n",
    "    \n",
    "    # 定义训练和验证数据加载器\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size = 1, shuffle = True, num_workers = 0,\n",
    "        collate_fn = utils.collate_fn)\n",
    "    \n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size = 1, shuffle = False, num_workers = 0,\n",
    "        collate_fn = utils.collate_fn)  \n",
    "    \n",
    "    num_classes = 2\n",
    "    model = get_model_instance_segmentation(num_classes)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # 优化器\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr = 0.005,\n",
    "                               momentum = 0.9, weight_decay = 0.0005)\n",
    "    \n",
    "    # 学习率调整\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                  step_size = 3,\n",
    "                                                  gamma = 0.1)\n",
    "    \n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        # train_one_epoch(model, optimizer, data_loader, device, epoch, 10)\n",
    "        # lr_scheduler.step()\n",
    "        try:\n",
    "            train_one_epoch(model, optimizer, data_loader, device, epoch, 10)\n",
    "            lr_scheduler.step()\n",
    "            evaluate(model, data_loader_test, device = device)\n",
    "        except RuntimeError as exception:\n",
    "            if \"out of memory\" in str(exception):\n",
    "                print(\"WARNING: out of memory\")\n",
    "            if hasattr(torch.cuda, 'empty_cache'):\n",
    "                torch.cuda.empty_cache()\n",
    "            else:\n",
    "                raise exception\n",
    "        # evaluate(model, data_loader_test, device = device)\n",
    "    print(\"Finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: out of memory\n",
      "WARNING: out of memory\n",
      "WARNING: out of memory\n",
      "WARNING: out of memory\n",
      "WARNING: out of memory\n",
      "WARNING: out of memory\n",
      "WARNING: out of memory\n",
      "WARNING: out of memory\n",
      "WARNING: out of memory\n",
      "WARNING: out of memory\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
